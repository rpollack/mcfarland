```{r}
library(tidyverse)
library(tidymodels)
tidymodels_prefer()
# library(Lahman)
library(doParallel)
library(rvest)
library(styler)
library(themis)
library(vip)
library(glue)
library(stringi)
library(xgboost)
library(lubridate)
library(probably)
library(finetune)
library(DALEXtra)
library(DALEX)
library(kableExtra)
library(googlesheets4)

# functions

get_player_explainer <- function(name) {
  predict_parts(explainer = explainer, new_observation = player_predictions |> filter(Name == name)) |>
    as_tibble() |>
    mutate(Name = name)
}
```

Annual update steps:
- Download new FanGraphs player data, set to the most recent season: https://www.fangraphs.com/leaders/major-league?stats=bat&lg=all&type=c%2C4%2C6%2C11%2C12%2C13%2C21%2C-1%2C41%2C-1%2C23%2C37%2C38%2C61%2C-1%2C-1%2C203%2C199%2C58%2C7&month=0&ind=1&team=0%2Cto&rost=0&players=0&startdate=&enddate=&season1=1871&season=2024&qual=1&pos=np&v_cr=202301
- Download new FG data that marks players as HOF: https://www.fangraphs.com/leaders/major-league?stats=bat&lg=all&type=8&month=0&ind=0&team=0%2Cto&rost=2&players=0&startdate=&enddate=&season1=1871&season=2023&qual=0&pos=np
- Download new MVP data from https://www.mlb.com/awards/most-valuable-player. Ensure it joins properly to the main baseball dataset. 
- Refresh Lahman DB data.
- Refresh BB-ref data to supplement whatever Lahman is missing. 
- Download new Chadwick data: https://github.com/chadwickbureau/register/tree/master/data
- Set 'hof consideration' year to the most recent one
- Set 'last season played' to the most recent one

Features to try:

investigate wrong predictions in training model (or predictions) & find a pattern. 

1. I’m noodling on more of a sliding scale for PEDs, like “named in leaked anonymous report”, “mentioned in Mitchell report only”, “served suspension”, “served multiple suspensions”, etc. 
1. scale_pos_weight
1. Positional data
4. Max Cumulative WAR with a franchise instead of max cumulative G
5. Gold Gloves (Lahman + BBREf to supplement)
6. Do this for Starting Pitchers!!! Features: IP, K, ER, ERA, WAR, age (obvs), awards voting. 
7. Use player's actual birthday for age
1. 'Career midpoint' year should be THROUGH THAT AGE as well.
1. Postseason play. 



load all data and build the initial data frame. 


```{r}
# get stats and data for position players.

# fg data: https://www.fangraphs.com/leaders/major-league?stats=bat&lg=all&type=c%2C4%2C6%2C11%2C12%2C13%2C21%2C-1%2C41%2C-1%2C23%2C37%2C38%2C61%2C-1%2C-1%2C203%2C199%2C58%2C7&month=0&ind=1&team=0%2Cto&rost=0&players=0&startdate=&enddate=&season1=1871&season=2024&qual=1&pos=np&v_cr=202301
batter_data <-
  read_csv("~/Downloads/fangraphs-leaderboards-26.csv", show_col_types = FALSE)

# chadwick data: https://github.com/chadwickbureau/register/tree/master. we will use this to compute franchise mobility as well as the years in which a player was most active
chadwick_data <-
  read_csv("~/Downloads/people-0.csv", col_select = c(key_fangraphs, key_retro, key_bbref, key_mlbam, key_uuid, key_fangraphs, key_retro, key_bbref, birth_year, mlb_played_first, mlb_played_last), show_col_types = FALSE) |>
  bind_rows(read_csv("~/Downloads/people-1.csv", col_select = c(key_fangraphs, key_retro, key_bbref, key_mlbam, key_uuid, key_fangraphs, key_retro, key_bbref, birth_year, mlb_played_first, mlb_played_last), show_col_types = FALSE)) |>
  bind_rows(read_csv("~/Downloads/people-2.csv", col_select = c(key_fangraphs, key_retro, key_bbref, key_mlbam, key_uuid, key_fangraphs, key_retro, key_bbref, birth_year, mlb_played_first, mlb_played_last), show_col_types = FALSE)) |>
  bind_rows(read_csv("~/Downloads/people-3.csv", col_select = c(key_fangraphs, key_retro, key_bbref, key_mlbam, key_uuid, key_fangraphs, key_retro, key_bbref, birth_year, mlb_played_first, mlb_played_last), show_col_types = FALSE)) |>
  bind_rows(read_csv("~/Downloads/people-4.csv", col_select = c(key_fangraphs, key_retro, key_bbref, key_mlbam, key_uuid, key_fangraphs, key_retro, key_bbref, birth_year, mlb_played_first, mlb_played_last), show_col_types = FALSE)) |>
  bind_rows(read_csv("~/Downloads/people-5.csv", col_select = c(key_fangraphs, key_retro, key_bbref, key_mlbam, key_uuid, key_fangraphs, key_retro, key_bbref, birth_year, mlb_played_first, mlb_played_last), show_col_types = FALSE)) |>
  bind_rows(read_csv("~/Downloads/people-6.csv", col_select = c(key_fangraphs, key_retro, key_bbref, key_mlbam, key_uuid, key_fangraphs, key_retro, key_bbref, birth_year, mlb_played_first, mlb_played_last), show_col_types = FALSE)) |>
  bind_rows(read_csv("~/Downloads/people-7.csv", col_select = c(key_fangraphs, key_retro, key_bbref, key_mlbam, key_uuid, key_fangraphs, key_retro, key_bbref, birth_year, mlb_played_first, mlb_played_last), show_col_types = FALSE)) |>
  bind_rows(read_csv("~/Downloads/people-8.csv", col_select = c(key_fangraphs, key_retro, key_bbref, key_mlbam, key_uuid, key_fangraphs, key_retro, key_bbref, birth_year, mlb_played_first, mlb_played_last), show_col_types = FALSE)) |>
  bind_rows(read_csv("~/Downloads/people-9.csv", col_select = c(key_fangraphs, key_retro, key_bbref, key_mlbam, key_uuid, key_fangraphs, key_retro, key_bbref, birth_year, mlb_played_first, mlb_played_last), show_col_types = FALSE)) |>
  bind_rows(read_csv("~/Downloads/people-a.csv", col_select = c(key_fangraphs, key_retro, key_bbref, key_mlbam, key_uuid, key_fangraphs, key_retro, key_bbref, birth_year, mlb_played_first, mlb_played_last), show_col_types = FALSE)) |>
  bind_rows(read_csv("~/Downloads/people-b.csv", col_select = c(key_fangraphs, key_retro, key_bbref, key_mlbam, key_uuid, key_fangraphs, key_retro, key_bbref, birth_year, mlb_played_first, mlb_played_last), show_col_types = FALSE)) |>
  bind_rows(read_csv("~/Downloads/people-c.csv", col_select = c(key_fangraphs, key_retro, key_bbref, key_mlbam, key_uuid, key_fangraphs, key_retro, key_bbref, birth_year, mlb_played_first, mlb_played_last), show_col_types = FALSE)) |>
  bind_rows(read_csv("~/Downloads/people-d.csv", col_select = c(key_fangraphs, key_retro, key_bbref, key_mlbam, key_uuid, key_fangraphs, key_retro, key_bbref, birth_year, mlb_played_first, mlb_played_last), show_col_types = FALSE)) |>
  bind_rows(read_csv("~/Downloads/people-e.csv", col_select = c(key_fangraphs, key_retro, key_bbref, key_mlbam, key_uuid, key_fangraphs, key_retro, key_bbref, birth_year, mlb_played_first, mlb_played_last), show_col_types = FALSE)) |>
  bind_rows(read_csv("~/Downloads/people-f.csv", col_select = c(key_fangraphs, key_retro, key_bbref, key_mlbam, key_uuid, key_fangraphs, key_retro, key_bbref, birth_year, mlb_played_first, mlb_played_last), show_col_types = FALSE))

# get HOF induction data
# hof players: https://www.fangraphs.com/leaders/major-league?stats=bat&lg=all&type=8&month=0&ind=0&team=0%2Cto&rost=2&players=0&startdate=&enddate=&season1=1871&season=2023&qual=0&pos=np

hof <-
  read_csv("~/Downloads/fangraphs-leaderboards-24.csv", col_select = "PlayerId", show_col_types = FALSE) |>
  mutate(hof = 1)

# get cumulative MVPs by year
mvp_html <-
  read_html("https://www.mlb.com/awards/most-valuable-player") |>
  html_elements("table")

al_mvp <-
  mvp_html |>
  pluck(1) |>
  html_table() |>
  mutate(Name = stri_trans_general(Player, id = "Latin-ASCII")) |>
  select(Year, Name) |>
  mutate(num_mvps = 1)

nl_mvp <-
  mvp_html |>
  pluck(2) |>
  html_table() |>
  mutate(Name = stri_trans_general(Player, id = "Latin-ASCII")) |>
  select(Year, Name) |>
  mutate(num_mvps = 1)

mvp_data <-
  bind_rows(al_mvp, nl_mvp)

# asg data is through 2023 at this point. group to player and year bc there were multiple ASG's for a few years
asg_data <-
  read_csv("~/Downloads/lahman_1871-2023_csv/lahman_1871-2023_csv/AllstarFull.csv", show_col_types = FALSE) |>
  distinct(playerID, yearID, gameID) |>
  count(playerID, yearID, name = "asg")

# as of this writing, Lahman MVP data goes through 2023. get it
mvp_lahman <-
  read_csv("~/Downloads/lahman_1871-2023_csv/lahman_1871-2023_csv/AwardsSharePlayers.csv", show_col_types = FALSE) |>
  filter(awardID == "Most Valuable Player") |>
  group_by(playerID, yearID) |>
  summarize(num_mvp_points = sum(pointsWon))

# supplement Lahman data with data from the most recent season
mvp_supplement_data <-
  read_html("https://www.baseball-reference.com/awards/awards_2024.shtml")


# get AL MVP supplement data and bind with NL data
mvp_supplement <-
  mvp_supplement_data |>
  html_elements("table") |>
  pluck(1) |>
  html_table(header = TRUE) |>
  select(Name = 2, num_mvp_points = 4) |>
  mutate(foo = as.numeric(num_mvp_points)) |>
  bind_rows(
    mvp_supplement_data |>
      # bind to NL MVP voting data
      html_elements("table") |>
      pluck(2) |>
      html_table(header = TRUE) |>
      select(Name = 2, num_mvp_points = 4) |>
      mutate(foo = as.numeric(num_mvp_points))
  ) |>
  filter(Name != "Name") |>
  mutate(Season = 2024) |>
  mutate(Name = stri_trans_general(Name, id = "Latin-ASCII")) |>
  select(Name, Season, foo)

glove_data <-
  read_csv("~/Downloads/lahman_1871-2023_csv/lahman_1871-2023_csv/AwardsPlayers.csv", show_col_types = FALSE) |>
  filter(awardID %in% c("Gold Glove", "Platinum Glove")) |>
  select(playerID, yearID, awardID) |>
  mutate(num = 1) |>
  pivot_wider(names_from = awardID, values_from = num) |>
  select(playerID, Season = yearID, num_plat_glove = `Platinum Glove`, num_gold_glove = `Gold Glove`)
```




engineer some features and create the useable data frame

```{r, echo=FALSE}
# TODO: we could do a thing where like we model whether the player's year was their last in the bigs. this could help inform predicting because the model will know when a player stopped accruing WAR.

hof_consideration_year <- 2024 # used to determine whether someone's been considered for the HOF

bat_data <-
  batter_data |>
  inner_join(chadwick_data, by = c("PlayerId" = "key_fangraphs")) |>
  mutate(
    age = Season - birth_year,
    career_midpoint_year = floor((mlb_played_first + mlb_played_last) / 2),
    # all the teams who've moved or changed names: dodgers, giants, marlins, orioles (browns, old brewers), expos (nationals), Tampa Bay (rays / devil rays), Braves, Brewers (Pilots?)

    # align historical franchise abbreviations to current day teams so we can compute how mobile a player is
    franchise = case_when(
      Team %in% c("FLA", "MIA") ~ "MIA",
      Team %in% c("SFG", "NYG") ~ "SFG",
      Team %in% c("ANA", "LAA", "CAL") ~ "LAA",
      Team %in% c("BRO", "LAD") ~ "LAD",
      Team %in% c("TBR", "TBD") ~ "TBR",
      Team %in% c("ATL", "BSN", "MLN") ~ "ATL",
      Team %in% c("OAK", "KCA", "PHA") ~ "OAK",
      Team %in% c("SLB", "BAL") ~ "BAL",

      # handle Senators/Twins
      Team %in% c("WAS", "MIN") ~ "MIN",

      # Expos/Nationals
      Team %in% c("WSN", "MON") ~ "WSN",

      # Other Senators / Rangers
      Team %in% c("TEX", "WSA") ~ "TEX",
      .default = Team
    )
  ) |>
  select(-key_uuid, -key_mlbam, -birth_year, -mlb_played_first) |>
  # make joining datasets easier by removing accent marks from names.
  mutate(Name = stri_trans_general(Name, id = "Latin-ASCII"))
```


merge in award and scandal data

```{r}
bat_data_seasonal <-
  bat_data |>
  # join ASG data from Lahman
  left_join(asg_data, by = c("key_bbref" = "playerID", "Season" = "yearID")) |>
  replace_na(list(asg = 0)) |>
  # supplement with 2024 ASG data which isn't in Lahman as of this time
  mutate(asg = case_when(
    Season == 2024 & Name %in% c("Ketel Marte", "Shohei Ohtani", "Trea Turner", "Bryce Harper", "William Contreras", "Christian Yelich", "Alec Bohm", "Teoscar Hernandez", "Jurickson Profar", "Paul Skenes", "Will Smith", "Pete Alonso", "Luis Arraez", "Freddie Freeman", "Ryan McMahon", "CJ Abrams", "Mookie Betts", "Elly de la Cruz", "Bryan Reynolds", "Jackson Merrill", "Heliot Ramos", "Fernando Tatis Jr.", "Marcell Ozuna", "Kyle Finnegan", "Max Fried", "Tyler Glasnow", "Hunter Greene", "Ryan Helsley", "Jeff Hoffman", "Shota Imanaga", "Reynaldo Lopez", "Chris Sale", "Cristopher Sanchez", "Tanner Scott", "Matt Strahm", "Ranger Suarez", "Robert Suarez", "Logan Webb", "Zack Wheeler", "Steven Kwan", "Gunnar Henderson", "Juan Soto", "Aaron Judge", "Yordan Alvarez", "Jose Ramirez", "Vladimir Guerrero Jr.", "Adley Rutschman", "Marcus Semien", "Corbin Burnes", "David Fry", "Salvador Perez", "Josh Naylor", "Jose Altuve", "Willi Castro", "Rafael Devers", "Isaac Paredes", "Jordan Westburg", "Carlos Correa", "Corey Seager", "Bobby Witt Jr.", "Riley Greene", "Jarren Duran", "Anthony Santander", "Kyle Tucker", "Tyler Anderson", "Emmanuel Clase", "Garrett Crochet", "Logan Gilbert", "Clay Holmes", "Tanner Houck", "Seth Lugo", "Mason Miller", "Andres Munoz", "Cole Ragans", "Tarik Skubal", "Kirby Yates") ~ asg + 1,
    .default = asg
  )) |>
  # mvp data from Lahman.
  left_join(mvp_lahman, by = c("key_bbref" = "playerID", "Season" = "yearID")) |>
  replace_na(list(num_mvp_points = 0)) |>
  # supplemental MVP data Lahman didn't have
  left_join(mvp_supplement, by = c("Name", "Season")) |>
  replace_na(list(foo = 0)) |>
  mutate(num_mvp_points = num_mvp_points + foo) |>
  select(-foo) |>
  left_join(glove_data, by = c("key_bbref" = "playerID", "Season")) |>
  replace_na(list(num_plat_glove = 0, num_gold_glove = 0)) |>
  # supplement plat & GG glove data with 2024 data, not in Lahman
  mutate(
    num_plat_glove = case_when(
      Season == 2024 & Name %in% c("Cal Raleigh", "Brice Turang") ~ num_plat_glove + 1,
      .default = num_plat_glove
    ),
    num_gold_glove = case_when(
      Season == 2024 & Name %in% c("Chris Sale", "Patrick Bailey", "Christian Walker", "Brice Turang", "Matt Chapman", "Ezequiel Tovar", "Brenton Doyle", "Ian Happ", "Sal Frelick", "Jared Triolo", "Seth Lugo", "Cal Raleigh", "Carlos Santana", "Andres Gimenez", "Alex Bregman", "Bobby Witt Jr.", "Daulton Varsho", "Wilyer Abreu", "Steven Kwan", "Dylan Moore") ~ num_gold_glove + 1,
      .default = num_gold_glove
    )
  ) |>
  # encode whether a player has been inducted into the HOF
  left_join(hof, by = "PlayerId") |>
  replace_na(list(hof = 0)) |>
  mutate(
    hof = factor(hof, levels = c(1, 0)) # positive class prediction must be first level
  ) |>
  filter(!is.na(age)) |> # there are 80-ish NA values for 'age', all players in the late 1800s. get rid of 'em
  mutate(
    scandal_type = case_when(
      Name %in% c("Barry Bonds", "Roger Clemens", "Jose Canseco", "Rafael Palmeiro", "Jason Giambi", "Gary Sheffield", "Miguel Tejada", "Nelson Cruz", "Andy Pettitte", "Ryan Braun", "Manny Ramirez", "Alex Rodriguez", "Mark McGwire", "Sammy Sosa", "Robinson Cano", "Starling Marte", "Melky Cabrera", "David Ortiz", "Dee Strange-Gordon", "Bartolo Colon", "Fernando Tatis Jr.") ~ "PEDs",
      Name %in% c("Joe Jackson", "Eddie Cicotte", "Buck Weaver", "Chick Gandil", "Fred McMullin", "Swede Risberg", "Lefty Williams", "Joe Gedeon", "Pete Rose") ~ "gambling",
      Name %in% c("Carlos Beltran", "Jose Altuve", "Alex Bregman", "Alex Cora", "Carlos Correa", "George Springer", "Gaylord Perry") ~ "cheating",
      Name %in% c("Curt Schilling", "Lenny Dykstra", "Roberto Alomar") ~ "misconduct",
      Name %in% c("Marcell Ozuna", "Roberto Osuna", "Jose Reyes", "Aroldis Chapman", "Omar Vizquel", "Addison Russell", "Wander Franco", "Domingo German") ~ "domestic violence",
      TRUE ~ "none"
    ),

    # round all numeric columns to 1 decimal place for simplicity and ease of presentation
    across(where(is.numeric), round, 1)
  )
```


make separate df for max franchise games per age for each player.
compute seasonal and cumulative stats for players.
then join the two datasets together.

```{r}
# compute max games a player has played with a franchise through that age.

max_franchise_games <-
  bat_data |>
  group_by(PlayerId, franchise) |>
  arrange(PlayerId, franchise, age) |>
  mutate(cumulative_franchise_g = cumsum(G)) |> # Step 1: Franchise-specific cumulative G
  ungroup() |>
  #    overall cumulative G for player through that point in career
  arrange(PlayerId, age) |>
  mutate(cumulative_career_g = cumsum(G)) |>
  group_by(PlayerId, Name) |>
  arrange(age) |>
  mutate(
    #   # compute the highest G total with 1 franchise to that point in the player's career
    max_cume_frnch_g = cummax(cumulative_franchise_g)
  ) |>
  # players traded midseason will have 2 rows still. to get to one row per age: for each age, find the maximum.
  group_by(PlayerId, Name, age) |>
  summarize(max_cume_frnch_g = max(max_cume_frnch_g)) |>
  ungroup()

# verify 1 row per player per age. the following should return 0
max_franchise_games |>
  count(PlayerId, age) |>
  filter(n > 1)


bat_data_full <-
  bat_data_seasonal |>
  # compute seasonal totals. players traded midseason have multiple rows
  group_by(PlayerId, Name, Season, age, mlb_played_last, career_midpoint_year, scandal_type, hof) |>
  summarize(
    season_WAR = sum(WAR),
    season_H = sum(H),
    season_HR = sum(HR),
    season_SB = sum(SB),
    
    # handle cases where there's a single thing (asg appearance, MVP vote total, etc) but multiple rows for the player-season (because they got traded midseason).
    # e.g. manny machado should have 1 ASG appearance for the 2018 season. Tony Taylor is a 2x all star. 
    season_num_asg = max(asg),  
    season_num_mvp_points = max(num_mvp_points),
    season_gold_glove = max(num_gold_glove),
    season_plat_glove = max(num_plat_glove)
  ) |>
  replace_na(list(season_SB = 0)) |>
  # now that each season/age is 1 row, compute cumulative WAR & other stats through each age
  group_by(PlayerId, Name, career_midpoint_year, mlb_played_last, scandal_type, hof) |>
  arrange(age, .by_group = TRUE) |>
  reframe(
    age = age,
    num_seasons = n(),
    cumulative_war = cumsum(season_WAR),
    cumulative_mvp_pts = cumsum(season_num_mvp_points),
    cumulative_hr = cumsum(season_HR),
    cumulative_h = cumsum(season_H),
    cumulative_sb = cumsum(season_SB),
    cumulative_asg = cumsum(season_num_asg),
    cumulative_gold_gloves = cumsum(season_gold_glove),
    cumulative_plat_gloves = cumsum(season_plat_glove)
  ) |>
  ungroup() |>
  left_join(max_franchise_games, by = c("PlayerId", "Name", "age")) |>
  mutate(considered_hof = if_else(hof_consideration_year - mlb_played_last < 6, FALSE, TRUE)) |>
  select(PlayerId, Name, age, contains("cumulative"), max_cume_frnch_g, mlb_played_last, career_midpoint_year, num_seasons, scandal_type, considered_hof, hof)


# test there is 1 row per player per age. the following should return 0 rows
bat_data_full |>
  count(PlayerId, age) |>
  filter(n > 1)
```


train the model and show information about it, such as a confusion matrix and AUPRC, and make predictions

```{r}
# make use of https://probably.tidymodels.org/articles/equivocal-zones.html ???

hof_split <-
  bat_data_full |>
  # train & test model only on players who have not played for 5 years
  filter(
    considered_hof,
    # thin out the dataset a bit. realistically you need to be somewhat of a consistent MLB regular before you're ACTUALLY considered. don't train on scrubs or short-termers.
    num_seasons >= 2
  ) |>
  # remove columns not needed for training
  select(-PlayerId, -Name, -num_seasons, -mlb_played_last, -considered_hof) |>
  initial_split(strata = hof)

hof_train <- training(hof_split)
hof_test <- testing(hof_split)

# build a specification.
xgb_spec <-
  boost_tree(
    mode = "classification",
    trees = tune(),
    tree_depth = tune(),
    min_n = tune(),
    loss_reduction = tune(),
    sample_size = tune(),
    # scale_pos_weight = tune(),
    # mtry = tune(),
    learn_rate = tune(),
    stop_iter = tune()
  ) |>
  set_engine("xgboost", validation = 0.2) # validation proportion to use for early stop detection

xgb_grid <- grid_space_filling(
  trees(),
  tree_depth(),
  min_n(),
  loss_reduction(),
  # scale_pos_weight = c(52,55),
  sample_size = sample_prop(),
  stop_iter(range = c(10, 50)), # tune early stopping rounds
  # mtry(range = c(6, 32)),
  # finalize(mtry(), hof_train |> dplyr::select(-hof)),
  learn_rate(),
  size = 50
)

xgb_recipe <-
  recipe(hof ~ ., data = hof_train) |>
  step_dummy_multi_choice(scandal_type) |>
  step_smote(hof) # smote increases AUPRC, bal acc, and F1 by a meaningful amount.

xgb_wf <-
  workflow() |>
  add_model(xgb_spec) |>
  add_recipe(xgb_recipe)

all_cores <- parallel::detectCores(logical = FALSE)
cl <- makePSOCKcluster(all_cores)
registerDoParallel(cl)

# find the optimal values of tuning parameters using 10-fold cross validation
hof_folds <- vfold_cv(hof_train, strata = hof)

xgb_res <- tune_grid(
  xgb_wf,
  resamples = hof_folds,
  grid = xgb_grid,
  control = control_grid(
    save_pred = TRUE,
    verbose = TRUE
  ),
  metrics = metric_set(pr_auc),
)

# show how each parameter affects the model performance
xgb_res |>
  collect_metrics() |>
  filter(.metric == "pr_auc") |>
  dplyr::select(mean, min_n:sample_size) |>
  pivot_longer(min_n:sample_size,
    values_to = "value",
    names_to = "parameter"
  ) |>
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(alpha = 0.8, show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "PR_AUC")

best_auprc <- select_best(xgb_res, metric = "pr_auc")

final_xgb <- finalize_workflow(
  xgb_wf,
  best_auprc
)

# fit model to training set and evaluate on test set.
final_res <-
  last_fit(final_xgb, hof_split)

# extract final model and use it to predict HOF chances

hof_mdl <- final_res$.workflow[[1]]

# evaluate model using curves & area underneath it

predictions <-
  final_res |>
  collect_predictions()

# find optimal threshold for class predictions by maximizing the j index
# players with a predicted HOF probability above this point will be classified as HOF
optimal_threshold <-
  predictions |>
  threshold_perf(hof, .pred_1, thresholds = seq(0.1, 1, by = 0.0025)) |>
  filter(.metric == "j_index") |>
  arrange(desc(.estimate)) |>
  filter(row_number() == 1) |>
  dplyr::select(.threshold) |>
  as.numeric()


optimal_threshold <- optimal_threshold * 100

# not sure this is adding any value
# optimal_predictions <-
#   predictions |>
#   mutate(optimized_pred = factor(if_else(.pred_1 >= optimal_threshold, 1, 0),
#                                  levels = c(1,0)))

# TODO: predictions_optimized <-
# preds_new <- preds %>%
# mutate(new_class_pred = factor(ifelse(.pred_bad >= max_j_index_threshold, "bad", "good"),
#                                levels = c("bad", "good")))

# compute area under ROC using class probabilities
area_under_curve <-
  predictions |>
  pr_auc(truth = hof, .pred_1) |>
  dplyr::select(.estimate) |>
  as.numeric() |>
  round(2)

# draw  PR Curve using class probabilities
predictions |>
  pr_curve(truth = hof, .pred_1) |>
  ggplot(aes(recall, precision)) +
  geom_path() +
  coord_equal() +
  geom_hline(yintercept = 0, color = "blue", lty = "dashed") +
  ggtitle("Precision-Recall Curve, HOF Prediction Model",
    subtitle = glue("Area Under Curve: {area_under_curve}")
  )

ggsave("hof-mdl-pr-curve.png")

predictions |>
  conf_mat(truth = hof, estimate = .pred_class) |>
  pluck(1) |>
  as_tibble() |>
  ggplot(aes(Prediction, Truth)) +
  geom_tile(show.legend = FALSE) +
  geom_text(aes(label = n), colour = "white", alpha = 1) +
  ggtitle("Confusion Matrix, HOF Prediction Model")

ggsave("hof-mdl-confusion-matrix.png")


predictions |>
  f_meas(truth = hof, estimate = .pred_class)

predictions |>
  bal_accuracy(truth = hof, estimate = .pred_class)

# show the importance of each variable. remove 'X's from positions for readibility
final_xgb |>
  fit(data = hof_train) |>
  extract_fit_parsnip() |>
  vip::vi() |>
  mutate(Variable = str_replace_all(Variable, "X", "")) |>
  ggplot(aes(reorder(Variable, Importance), Importance)) +
  geom_col() +
  coord_flip() +
  labs(x = "") +
  ggtitle("Relative Predictor Importance, HOF Prediction Model")

ggsave("hof-mdl-variable-importance.png")

# Create an explainer using training data
explainer <- explain_tidymodels(hof_mdl,
  data = hof_train,
  y = as.numeric(hof_train$hof),

  # tell the explainer that a value of hof = 1 is a positive prediction
  predict_function_target_column = 1,
  verbose = FALSE
)
```


make predictions!!

``` {r}
# predict HOF chances for players who meet the following criteria:
# have not been considered for the HOF
# last played in the past 2 years (e.g. likely are still active) OR
# have at least 10 seasons in the majors (they are eligible at some point soon)
# this avoids predicting players like Brandon Webb and Josh Hamilton
# who are retired but didn't play 10 years so aren't eligible and will never be

year_threshold <- 2
last_season_played <- 2024

prep <-
  bat_data_full |>
  group_by(PlayerId) |>
  mutate(num_seasons_real = n_distinct(age)) |>
  ungroup() |>
  # remove guys not already in the Hall but who've played for at least 10 seasons or were active recently
  # remove those who've been considered, because they were in the training data
  filter(
    hof != 1,
    !considered_hof,
    (num_seasons_real >= 10 |
      num_seasons_real < 10 & mlb_played_last >= (last_season_played - year_threshold))
  ) |>
  # get most recent stats for all players
  group_by(PlayerId) |>
  filter(age == max(age)) |>
  ungroup()

final_predictions <- predict(hof_mdl, prep, type = "prob")

player_predictions <-
  bind_cols(prep, final_predictions) |>
  mutate(
    prob_hof = round(100 * .pred_1, 1),
    pred_hof = if_else(prob_hof >= optimal_threshold, TRUE, FALSE)
  ) |>
  arrange(desc(pred_hof), desc(prob_hof)) |>
  select(Name, age, pred_hof, cumulative_war, cumulative_h, cumulative_hr, cumulative_mvp_pts, scandal_type, career_midpoint_year, max_cume_frnch_g, cumulative_sb, cumulative_gold_gloves, cumulative_plat_gloves, cumulative_asg) |>
  ungroup()

player_predictions |>
  group_by(pred_hof) |>
  slice_head(n = num_hof) |>
  kbl() |>
  kable_styling()

player_predictions |>
  write_sheet("https://docs.google.com/spreadsheets/d/12uWa6dZaKnglJiXpE_fDZ5mCPrQ0rlQLrho6vlN6Jm8/edit?gid=0#gid=0", sheet = "Predictions")
```


'intercept' is the mean value of predictions in the dataset (?) so the starting point.


```{r}
# Compare 2 players of the same age, 1 predicted OF and the other not


# age 24
obvs <- "Bobby Witt Jr."
predict_parts(explainer = explainer, new_observation = player_predictions |> filter(Name == obvs)) |>
  arrange(contribution) |>
  plot()

obvs <- "Gabriel Moreno"
predict_parts(explainer = explainer, new_observation = player_predictions |> filter(Name == obvs)) |>
  arrange(contribution) |>
  plot()

# age 27

obvs <- "Yordan Alvarez"
predict_parts(explainer = explainer, new_observation = player_predictions |> filter(Name == obvs)) |>
  arrange(contribution) |>
  plot()

obvs <- "Jeremy Pena"
predict_parts(explainer = explainer, new_observation = player_predictions |> filter(Name == obvs)) |>
  arrange(contribution) |>
  plot()
```


```{r, fig.width=5, fig.height=7}
# TODO: think about how to show a player's overall percentage and how each of these add up. the base plotting function does that but they don't align the scales, so it makes it hard to compare.

c("Robinson Cano", "Josh Donaldson", "Shohei Ohtani", "Gunnar Henderson") |>
  map(get_player_explainer) |>
  list_rbind() |>
  select(Name, variable, contribution) |>
  filter(variable != "intercept" & variable != "prediction") |>
  ggplot(aes(contribution, variable)) +
  geom_col() +
  facet_grid(vars(Name), scales = "free_y") +
  labs(y = "")
```


```{r}
# Function to turn explanations into human-readable text
generate_english_explanation <- function(row_index, explainer, data_row) {
  # Ensure the row is in the correct format (single-row tibble)
  # data_row <- data_row |>
  #   mutate(across(everything(), ~ if (is.list(.)) unlist(.) else .))

  print(data_row)
  str(data_row)
  # Generate explanations for the row
  explanation <- predict_parts(explainer = explainer, new_observation = data_row)

  # Extract contributions and format as English text
  details <- explanation %>%
    mutate(
      sentence = case_when(
        variable == "(Intercept)" ~ glue("The base prediction starts at {round(contribution, 2)}."),
        TRUE ~ glue("The feature '{variable}' contributes {round(contribution, 2)} to the prediction.")
      )
    )

  # Combine into a single human-readable explanation
  glue(
    "For observation {row_index}, the prediction process can be described as:\n",
    paste(details$sentence, collapse = " "),
    "\nThe final predicted value is {round(sum(details$contribution), 2)}."
  )
}

# prepare the dataset used to generate the explainers

# Generate explanations for each row using purrr::map2_chr
english_explanations <- map2_chr(
  1:nrow(explainer_prep),
  split(explainer_prep, 1:nrow(explainer_prep)), # Split into single-row tibbles
  ~ generate_english_explanation(.x, explainer, .y)
)

# Print the explanations
cat(paste(english_explanations, collapse = "\n\n"))
```
