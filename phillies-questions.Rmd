```{r setup, include=FALSE}
library(tidyverse)
library(xgboost)
library(caret)

# define plot aesthetics
fgt = theme(
  panel.background = element_rect(color = "lightgrey", fill = "white"),
  axis.title = element_text(family = "Lato"),
  axis.text = element_text(family = "Lato"),
  legend.title = element_text(family = "Lato"),
  legend.text = element_text(family = "Lato"),
  legend.background = element_rect(fill = "white"),
  legend.key = element_rect(fill = "white"),
  plot.title = element_text(family = "Lato"),
  panel.grid.major = element_line(size = .1, color = "lightgrey"),
  panel.grid.minor = element_line(size = 0),
  strip.text = element_text(family="Lato")
)

```

# Introduction

## What is this Analysis?
This project predicts second-half strikeout rates for a select group of pitchers.

## Why is it Important?

# Analysis

The following code chunks get data, train a model, apply the model results, and evaluate the predictions made.

## Get Data

In addition to the information provided in strikeouts.csv, I found the following data useful:

```{r message=FALSE, warning=FALSE, include=FALSE}

# get data from the first half of 2017
# source: https://questionnaire-148920.appspot.com/qa/
pitcher_data <- read_csv("~/Downloads/strikeouts.csv")

# get throwing hand of pitchers
# source: fangraphs
pitcher_handedness <- read_csv("pitcher_handedness.csv")

# get strikeout rates from 2016
# source: fangraphs
pitcher_data_2016 <- read_csv("2016-strikeout-rates.csv")

# combine datasets into one tibble
pitchers_2017 <- inner_join(pitcher_data, pitcher_handedness, by=c("fangraphs_id" = "PlayerId")) %>%
  inner_join(pitcher_data_2016, by=c("fangraphs_id" = "PlayerId"))
```

## Training the Model
The following code chunk creates a training dataset and then trains the model. I use the caret package to define a grid of tuning parameters for the xgboost algorithm and then perform 10-fold cross validation with each set of parameters. The final model is the one that minimizes the RMSE of the predictions.

```{r train model, message=FALSE, include=FALSE}

# create training dataset by removing unnecessary predictors
pitchers_2017_train <- 
  pitchers_2017 %>% 
  select(-fangraphs_id, -`2ndHalfIP`, -Name, -Team)

# set seed for reproducibility
set.seed(6)

# establish grid of parameters for xgboost algorithm
parameter_grid <- expand.grid(
  nrounds = c(25, 50, 100), 
  eta = c(0, .01, 0.1),
  max_depth = c(5, 10, 15, 20),
  gamma = c(0, 1, 2, 5),
  colsample_bytree = c(0.1, 0.5, 0.9),
  min_child_weight = c(0, 0.1),
  subsample = c(0.1, 0.2, 0.5, 0.7))

# establish k-fold cross-validation and other tuning
control_parameters <- trainControl(method = "cv",
                                   number = 10,
                                   search = "grid",
                                   allowParallel = TRUE)

#find the besttrain model using methodology tuning parameters above
second_half_k_predictor <- train(`2ndHalfK%` ~ .,
                                 data = pitchers_2017_train,
                                 method = "xgbTree",
                                 trControl = control_parameters,
                                 tuneGrid = parameter_grid,
                                 metric = "RMSE")
```

## Predicting Second-Half Strikeout Rates

The next code chunk uses the model to predict the second-half K% for each pitcher. It also calculates the RMSE of the predictions and the R^2 of the best-fit line between the predicted and actual values. I'll use these values later to evaluate the model itself.

```{r predict results}

# predict second-half k% using model
# transform to tibble for binding to original tibble
# rename variable for clarity
second_half_pitcher_predictions <-
  predict(second_half_k_predictor, newdata = pitchers_2017_train) %>% 
  as_tibble() %>%
  select(`pred_2ndHalfK%` = value)

# augment original dataset with predictions
pitchers_2017_predicted <- 
  pitchers_2017 %>%
  bind_cols(second_half_pitcher_predictions)

# calculate actual values, predicted values, and residuals for model analysis purposes
results <- pitchers_2017_predicted %>%
  select(Name,
         predicted_second_half_k_rate = `pred_2ndHalfK%`,
         actual_second_half_k_rate = `2ndHalfK%`) %>%
  mutate(residual = actual_second_half_k_rate - predicted_second_half_k_rate)


```

## Evaluating Results

I evaluate the model in two ways. The first way is to plot the predicted vs. actual values and see the R^2 of the line of best fit. The following plot shows this information:

```{r plot results, echo=FALSE}

# calculate R^2 to see how much variance the model explains
model_fit <- lm(results$actual_second_half_k_rate ~ results$predicted_second_half_k_rate)
r_squared <- round(summary(model_fit)$r.squared, 3)

# plot predicted vs. actual values
results %>%  
  ggplot(aes(predicted_second_half_k_rate, actual_second_half_k_rate)) + geom_point() + fgt +
  labs(x="Predicted Second-Half K%", y="Actual Second-Half K%", caption = sprintf("R^2: %s", r_squared)) +
  ggtitle("2017 Second-Half K%: Predicted Rates vs. Actual Rates") +
  xlim(0, 0.5) + ylim(0, 0.5) + geom_smooth(method="lm")
```

The scatterplot shows the tight fit between the model's predicted results and the actual results. The R^2 of this fit shows that the model explains 96% of the variance in the actual second-half K rates.

The next plot shows the predicted values vs. the residuals of each predicted value, as well as the RMSE of the predictions:

```{r plot residuals, echo=FALSE, fig.align='center'}

# calculate RMSE
rmse <- round(
  RMSE(results$predicted_second_half_k_rate, results$actual_second_half_k_rate),
  3)

# plot fitted vs. residuals to identify bias
results %>%
  ggplot(aes(predicted_second_half_k_rate, residual)) + geom_point() + fgt +
  labs(x="Predicted Second-Half K%", y="Residual", caption = sprintf("RMSE: %s", rmse))+
  ggtitle("2017 Second-Half K%: Predicted Rates vs. Residuals") +
  xlim(0, .5)

```

The plot shows some skew to the residuals, but not an unreasonable amount. The RMSE of the predictions is 0.015, or 1.5 percentage points of second-half strikeout rate.

All models can be improved. But based on the 0.962 R^2, the reasonable-looking plot of the residuals, and the low RMSE of 0.015, this model is an excellent base from which to start making predictions. 

The final code chunk creates a CSV file of predicted and actual second-half K rates for each pitcher, for ease of distribution. It also saves the model itself to a file so it can be used to reproduce results later.

```{r show results, include=FALSE}
results %>%
  select(-residual) %>%
  write_csv("k-rate-predictions.csv")

# save model to a file so it can be used later.
saveRDS(second_half_k_predictor, "phillies-k-rate-predictor.rds")
```

