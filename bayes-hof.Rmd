```{r}
library(tidyverse)
library(tidymodels)
tidymodels_prefer()
# library(Lahman)
library(doParallel)
library(rvest)
library(styler)
library(themis)
library(vip)
library(glue)
library(stringi)
library(xgboost)
library(lubridate)
library(probably)
library(finetune)
library(DALEXtra)
library(DALEX)
library(kableExtra)

# functions

get_player_explainer <- function(name) {
  predict_parts(explainer = explainer, new_observation = player_predictions |> filter(Name == name)) |>
    as_tibble() |>
    mutate(Name = name)
}

get_all_star_rosters <- function(year) {
  # TODO: handle years with multiple all star games.

  if (!year %in% c(1945, 2020)) {
    read_html(glue("https://www.baseball-reference.com/allstar/{year}-allstar-game.shtml")) |>
      html_element(xpath = "//*[@id='all_lineups']/comment()") |>
      html_text() |>
      str_extract_all(bref_id_regex) |>
      as_tibble(.name_repair = "minimal") |>
      select(brefid = 1) |>
      mutate(Season = year)
  }
}

get_mvp_voting <- function(year) {
  # wait a random a mount of seconds in between 4 and 125
  Sys.sleep(floor(runif(n = 1, min = 125, max = 320)))

  awards_html <-
    read_html(glue("https://www.baseball-reference.com/awards/awards_{year}.shtml"))

  al_points <-
    awards_html |>
    html_elements(css = "#AL_MVP_voting") |>
    html_table() |>
    pluck(1) |>
    dplyr::select(mvp_points = 4) |>
    filter(row_number() != 1) |>
    mutate(mvp_points = as.numeric(mvp_points))

  al_player_ids <- awards_html |>
    html_element(css = "#AL_MVP_voting") |>
    html_elements("td") |>
    html_attr("data-append-csv") |>
    as_tibble() |>
    filter(!is.na(value))

  al_data <-
    bind_cols(al_player_ids, al_points)

  nl_points <-
    awards_html |>
    html_elements(css = "#NL_MVP_voting") |>
    html_table() |>
    pluck(1) |>
    dplyr::select(mvp_points = 4) |>
    filter(row_number() != 1) |>
    mutate(mvp_points = as.numeric(mvp_points))

  nl_player_ids <- awards_html |>
    html_element(css = "#NL_MVP_voting") |>
    html_elements("td") |>
    html_attr("data-append-csv") |>
    as_tibble() |>
    filter(!is.na(value))

  nl_data <-
    bind_cols(nl_player_ids, nl_points)

  bind_rows(al_data, nl_data) |>
    mutate(season = year)
}

get_cy_young_voting_points <- function(year) {
  awards_html <- read_html(glue("https://www.baseball-reference.com/awards/awards_{year}.shtml"))

  if (year < 1967) {
    ml <-
      awards_html |>
      html_elements(xpath = "//*[@id='all_ML_CYA_voting']/comment()") |>
      html_text()

    ml_ids <-
      ml |>
      str_extract_all(bref_id_regex) |>
      as_tibble(.name_repair = "minimal") |>
      dplyr::select(refid = 1) |>
      distinct()

    ml_points <-
      ml |>
      str_extract_all('(?<=_won" >)[:digit:]{1,3}\\.0') |>
      as_tibble(.name_repair = "minimal") |>
      dplyr::select(cya_points = 1) |>
      mutate(cya_points = as.numeric(cya_points))

    bind_cols(ml_ids, ml_points) |>
      mutate(Season = year)
  } else {
    al <-
      awards_html |>
      html_elements(xpath = "//*[@id='all_AL_CYA_voting']/comment()") |>
      html_text()

    al_ids <-
      al |>
      str_extract_all(bref_id_regex) |>
      as_tibble(.name_repair = "minimal") |>
      dplyr::select(refid = 1) |>
      distinct()

    al_points <-
      al |>
      str_extract_all('(?<=_won" >)[:digit:]{1,3}\\.0') |>
      as_tibble(.name_repair = "minimal") |>
      dplyr::select(cya_points = 1) |>
      mutate(cya_points = as.numeric(cya_points))

    al_data <- bind_cols(al_ids, al_points)

    nl <-
      awards_html |>
      html_elements(xpath = "//*[@id='all_NL_CYA_voting']/comment()") |>
      html_text()

    nl_ids <-
      nl |>
      str_extract_all(bref_id_regex) |>
      as_tibble(.name_repair = "minimal") |>
      dplyr::select(refid = 1) |>
      distinct()

    nl_points <-
      nl |>
      str_extract_all('(?<=_won" >)[:digit:]{1,3}\\.0') |>
      as_tibble(.name_repair = "minimal") |>
      dplyr::select(cya_points = 1) |>
      mutate(cya_points = as.numeric(cya_points))

    nl_data <- bind_cols(nl_ids, nl_points)

    bind_rows(al_data, nl_data) |>
      mutate(Season = year)
  }
}

get_silver_sluggers <- function(league) {
  read_html(glue("https://www.baseball-reference.com/awards/silver_slugger_{league}.shtml")) |>
    html_element("table") |>
    html_elements("a") |>
    html_attr("href") |>
    as_tibble() |>
    mutate(
      refid = str_extract(value, bref_id_regex),
      Season = str_extract(value, "[:digit:]{4}")
    ) |>
    fill(Season) |>
    na.omit() |>
    # remove the last 9 rows; as these are the 'multiple award winners'
    filter(row_number() <= n() - 9) |>
    dplyr::select(refid, Season) |>
    mutate(
      silver_slugger = 1,
      Season = as.numeric(Season)
    )
}

get_gold_gloves <- function(league) {
  read_html(glue("https://www.baseball-reference.com/awards/gold_glove_{league}.shtml")) |>
    html_element("table") |>
    html_elements("a") |>
    html_attr("href") |>
    as_tibble() |>
    mutate(
      refid = str_extract(value, bref_id_regex),
      Season = str_extract(value, "[:digit:]{4}")
    ) |>
    fill(Season) |>
    na.omit() |>
    # remove the last 9 rows; as these are the 'multiple award winners'
    filter(row_number() <= n() - 9) |>
    dplyr::select(refid, Season) |>
    mutate(
      gold_glove = 1,
      Season = as.numeric(Season)
    )
}
```

Annual update steps:
- Download new FanGraphs player data, set to the most recent season: https://www.fangraphs.com/leaders/major-league?stats=bat&lg=all&type=c%2C4%2C6%2C11%2C12%2C13%2C21%2C-1%2C41%2C-1%2C23%2C37%2C38%2C61%2C-1%2C-1%2C203%2C199%2C58%2C7&month=0&ind=1&team=0%2Cto&rost=0&players=0&startdate=&enddate=&season1=1871&season=2024&qual=1&pos=np&v_cr=202301
- Download new FG data that marks players as HOF: https://www.fangraphs.com/leaders/major-league?stats=bat&lg=all&type=8&month=0&ind=0&team=0%2Cto&rost=2&players=0&startdate=&enddate=&season1=1871&season=2023&qual=0&pos=np
- Download new MVP data from https://www.mlb.com/awards/most-valuable-player. Ensure it joins properly to the main baseball dataset. 
- Refresh Lahman DB data.
- Download new Chadwick data: https://github.com/chadwickbureau/register/tree/master/data
- Set 'hof consideration' year to the most recent one
- Set 'last season played' to the most recent one

Features to try:

investigate wrong predictions in training model (or predictions) & find a pattern. 

1. scale_pos_weight
1. 'Career midpoint' year should be THROUGH THAT AGE as well.
1. Add franchise continuity for the Senators and the Twins
1. Positional data
4. Max Cumulative WAR with a franchise instead of max cumulative G
5. Gold Gloves (Lahman)
6. Do this for Starting Pitchers!!! Features: IP, K, ER, ERA, WAR, age (obvs), awards voting. 
7. Use player's actual birthday for age


load all data


```{r}
# get stats and data for position players.

# fg data: https://www.fangraphs.com/leaders/major-league?stats=bat&lg=all&type=c%2C4%2C6%2C11%2C12%2C13%2C21%2C-1%2C41%2C-1%2C23%2C37%2C38%2C61%2C-1%2C-1%2C203%2C199%2C58%2C7&month=0&ind=1&team=0%2Cto&rost=0&players=0&startdate=&enddate=&season1=1871&season=2024&qual=1&pos=np&v_cr=202301
batter_data <-
  read_csv("~/Downloads/fangraphs-leaderboards-26.csv", show_col_types = FALSE)

# chadwick data: https://github.com/chadwickbureau/register/tree/master. we will use this to compute franchise mobility as well as the years in which a player was most active
chadwick_data <-
  read_csv("~/Downloads/people-0.csv", col_select = c(key_fangraphs, key_retro, key_bbref, key_mlbam, key_uuid, key_fangraphs, key_retro, key_bbref, birth_year, mlb_played_first, mlb_played_last), show_col_types = FALSE) |>
  bind_rows(read_csv("~/Downloads/people-1.csv", col_select = c(key_fangraphs, key_retro, key_bbref, key_mlbam, key_uuid, key_fangraphs, key_retro, key_bbref, birth_year, mlb_played_first, mlb_played_last), show_col_types = FALSE)) |>
  bind_rows(read_csv("~/Downloads/people-2.csv", col_select = c(key_fangraphs, key_retro, key_bbref, key_mlbam, key_uuid, key_fangraphs, key_retro, key_bbref, birth_year, mlb_played_first, mlb_played_last), show_col_types = FALSE)) |>
  bind_rows(read_csv("~/Downloads/people-3.csv", col_select = c(key_fangraphs, key_retro, key_bbref, key_mlbam, key_uuid, key_fangraphs, key_retro, key_bbref, birth_year, mlb_played_first, mlb_played_last), show_col_types = FALSE)) |>
  bind_rows(read_csv("~/Downloads/people-4.csv", col_select = c(key_fangraphs, key_retro, key_bbref, key_mlbam, key_uuid, key_fangraphs, key_retro, key_bbref, birth_year, mlb_played_first, mlb_played_last), show_col_types = FALSE)) |>
  bind_rows(read_csv("~/Downloads/people-5.csv", col_select = c(key_fangraphs, key_retro, key_bbref, key_mlbam, key_uuid, key_fangraphs, key_retro, key_bbref, birth_year, mlb_played_first, mlb_played_last), show_col_types = FALSE)) |>
  bind_rows(read_csv("~/Downloads/people-6.csv", col_select = c(key_fangraphs, key_retro, key_bbref, key_mlbam, key_uuid, key_fangraphs, key_retro, key_bbref, birth_year, mlb_played_first, mlb_played_last), show_col_types = FALSE)) |>
  bind_rows(read_csv("~/Downloads/people-7.csv", col_select = c(key_fangraphs, key_retro, key_bbref, key_mlbam, key_uuid, key_fangraphs, key_retro, key_bbref, birth_year, mlb_played_first, mlb_played_last), show_col_types = FALSE)) |>
  bind_rows(read_csv("~/Downloads/people-8.csv", col_select = c(key_fangraphs, key_retro, key_bbref, key_mlbam, key_uuid, key_fangraphs, key_retro, key_bbref, birth_year, mlb_played_first, mlb_played_last), show_col_types = FALSE)) |>
  bind_rows(read_csv("~/Downloads/people-9.csv", col_select = c(key_fangraphs, key_retro, key_bbref, key_mlbam, key_uuid, key_fangraphs, key_retro, key_bbref, birth_year, mlb_played_first, mlb_played_last), show_col_types = FALSE)) |>
  bind_rows(read_csv("~/Downloads/people-a.csv", col_select = c(key_fangraphs, key_retro, key_bbref, key_mlbam, key_uuid, key_fangraphs, key_retro, key_bbref, birth_year, mlb_played_first, mlb_played_last), show_col_types = FALSE)) |>
  bind_rows(read_csv("~/Downloads/people-b.csv", col_select = c(key_fangraphs, key_retro, key_bbref, key_mlbam, key_uuid, key_fangraphs, key_retro, key_bbref, birth_year, mlb_played_first, mlb_played_last), show_col_types = FALSE)) |>
  bind_rows(read_csv("~/Downloads/people-c.csv", col_select = c(key_fangraphs, key_retro, key_bbref, key_mlbam, key_uuid, key_fangraphs, key_retro, key_bbref, birth_year, mlb_played_first, mlb_played_last), show_col_types = FALSE)) |>
  bind_rows(read_csv("~/Downloads/people-d.csv", col_select = c(key_fangraphs, key_retro, key_bbref, key_mlbam, key_uuid, key_fangraphs, key_retro, key_bbref, birth_year, mlb_played_first, mlb_played_last), show_col_types = FALSE)) |>
  bind_rows(read_csv("~/Downloads/people-e.csv", col_select = c(key_fangraphs, key_retro, key_bbref, key_mlbam, key_uuid, key_fangraphs, key_retro, key_bbref, birth_year, mlb_played_first, mlb_played_last), show_col_types = FALSE)) |>
  bind_rows(read_csv("~/Downloads/people-f.csv", col_select = c(key_fangraphs, key_retro, key_bbref, key_mlbam, key_uuid, key_fangraphs, key_retro, key_bbref, birth_year, mlb_played_first, mlb_played_last), show_col_types = FALSE))

# get HOF induction data
# hof players: https://www.fangraphs.com/leaders/major-league?stats=bat&lg=all&type=8&month=0&ind=0&team=0%2Cto&rost=2&players=0&startdate=&enddate=&season1=1871&season=2023&qual=0&pos=np

hof <-
  read_csv("~/Downloads/fangraphs-leaderboards-24.csv", col_select = "PlayerId", show_col_types = FALSE) |>
  mutate(hof = 1)

# get cumulative MVPs by year
mvp_html <-
  read_html("https://www.mlb.com/awards/most-valuable-player") |>
  html_elements("table")

al_mvp <-
  mvp_html |>
  pluck(1) |>
  html_table() |>
  mutate(Name = stri_trans_general(Player, id = "Latin-ASCII")) |>
  select(Year, Name) |>
  mutate(num_mvps = 1)

nl_mvp <-
  mvp_html |>
  pluck(2) |>
  html_table() |>
  mutate(Name = stri_trans_general(Player, id = "Latin-ASCII")) |>
  select(Year, Name) |>
  mutate(num_mvps = 1)

mvp_data <-
  bind_rows(al_mvp, nl_mvp)

# asg data is through 2023 at this point. group to player and year bc there were multiple ASG's for a few years
asg_data <-
  read_csv("~/Downloads/lahman_1871-2023_csv/lahman_1871-2023_csv/AllstarFull.csv", show_col_types = FALSE) |>
  distinct(playerID, yearID, gameID) |>
  count(playerID, yearID, name = "asg")

# as of this writing, Lahman MVP data goes through 2023. get it
mvp_lahman <-
  read_csv("~/Downloads/lahman_1871-2023_csv/lahman_1871-2023_csv/AwardsSharePlayers.csv", show_col_types = FALSE) |>
  filter(awardID == "Most Valuable Player") |>
  group_by(playerID, yearID) |>
  summarize(num_mvp_points = sum(pointsWon))

# supplement Lahman data with data from the most recent season
mvp_supplement_data <-
  read_html("https://www.baseball-reference.com/awards/awards_2024.shtml")


# get AL MVP supplement data and bind with NL data
mvp_supplement <-
  mvp_supplement_data |>
  html_elements("table") |>
  pluck(1) |>
  html_table(header = TRUE) |>
  select(Name = 2, num_mvp_points = 4) |>
  mutate(foo = as.numeric(num_mvp_points)) |>
  bind_rows(
    mvp_supplement_data |>
      # bind to NL MVP voting data
      html_elements("table") |>
      pluck(2) |>
      html_table(header = TRUE) |>
      select(Name = 2, num_mvp_points = 4) |>
      mutate(foo = as.numeric(num_mvp_points))
  ) |>
  filter(Name != "Name") |>
  mutate(Season = 2024) |>
  mutate(Name = stri_trans_general(Name, id = "Latin-ASCII")) |>
  select(Name, Season, foo)
```

engineer some features and create the useable data frame

```{r, echo=FALSE}
# TODO: we could do a thing where like we model whether the player's year was their last in the bigs. this could help inform predicting because the model will know when a player stopped accruing WAR.


hof_consideration_year <- 2024 # used to determine whether someone's been considered for the HOF

bat_data <-
  batter_data |>
  inner_join(chadwick_data, by = c("PlayerId" = "key_fangraphs")) |>
  mutate(
    age = Season - birth_year,
    career_midpoint_year = floor((mlb_played_first + mlb_played_last) / 2),

    # all the teams who've moved or changed names: dodgers, giants, marlins, orioles (browns, old brewers), expos (nationals), Tampa Bay (rays / devil rays), Braves, Brewers (Pilots?)

    # align historical franchise abbreviations to current day teams so we can compute how mobile a player is
    franchise = case_when(
      Team %in% c("FLA", "MIA") ~ "MIA",
      Team %in% c("SFG", "NYG") ~ "SFG",
      Team %in% c("ANA", "LAA", "CAL") ~ "LAA",
      Team %in% c("BRO", "LAD") ~ "LAD",
      Team %in% c("TBR", "TBD") ~ "TBR",
      Team %in% c("ATL", "BSN", "MLN") ~ "ATL",
      Team %in% c("OAK", "KCA", "PHA") ~ "OAK",
      Team %in% c("SLB", "BAL") ~ "BAL",
      Team %in% c("WSN", "MON") ~ "WAS",
      Team %in% c("TEX", "WSA") ~ "TEX",
      .default = Team
    )
  )

bat_data_full <-
  bat_data |>
  mutate(Name = stri_trans_general(Name, id = "Latin-ASCII")) |>
  # join ASG data from Lahman
  left_join(asg_data, by = c("key_bbref" = "playerID", "Season" = "yearID")) |>
  replace_na(list(asg = 0)) |>
  # supplement with 2024 ASG data which isn't in Lahman as of this time
  mutate(asg = case_when(
    Season == 2024 & Name %in% c("Ketel Marte", "Shohei Ohtani", "Trea Turner", "Bryce Harper", "William Contreras", "Christian Yelich", "Alec Bohm", "Teoscar Hernandez", "Jurickson Profar", "Paul Skenes", "Will Smith", "Pete Alonso", "Luis Arraez", "Freddie Freeman", "Ryan McMahon", "CJ Abrams", "Mookie Betts", "Elly de la Cruz", "Bryan Reynolds", "Jackson Merrill", "Heliot Ramos", "Fernando Tatis Jr.", "Marcell Ozuna", "Kyle Finnegan", "Max Fried", "Tyler Glasnow", "Hunter Greene", "Ryan Helsley", "Jeff Hoffman", "Shota Imanaga", "Reynaldo Lopez", "Chris Sale", "Cristopher Sanchez", "Tanner Scott", "Matt Strahm", "Ranger Suarez", "Robert Suarez", "Logan Webb", "Zack Wheeler", "Steven Kwan", "Gunnar Henderson", "Juan Soto", "Aaron Judge", "Yordan Alvarez", "Jose Ramirez", "Vladimir Guerrero Jr.", "Adley Rutschman", "Marcus Semien", "Corbin Burnes", "David Fry", "Salvador Perez", "Josh Naylor", "Jose Altuve", "Willi Castro", "Rafael Devers", "Isaac Paredes", "Jordan Westburg", "Carlos Correa", "Corey Seager", "Bobby Witt Jr.", "Riley Greene", "Jarren Duran", "Anthony Santander", "Kyle Tucker", "Tyler Anderson", "Emmanuel Clase", "Garrett Crochet", "Logan Gilbert", "Clay Holmes", "Tanner Houck", "Seth Lugo", "Mason Miller", "Andres Munoz", "Cole Ragans", "Tarik Skubal", "Kirby Yates") ~ asg + 1,
    .default = asg
  )) |>
  # mvp data from Lahman.
  left_join(mvp_lahman, by = c("key_bbref" = "playerID", "Season" = "yearID")) |>
  replace_na(list(num_mvp_points = 0)) |>
  # supplemental data Lahman didn't have
  left_join(mvp_supplement, by = c("Name", "Season")) |>
  replace_na(list(foo = 0)) |>
  mutate(num_mvp_points = num_mvp_points + foo) |>
  select(-foo) |>
 
  # find the largest number of games a player has played with any 1 franchise through that point in their career.   # #https://www.billjamesonline.com/vagabonds_and_homebodies/
  group_by(PlayerId, franchise) |>
  arrange(PlayerId, franchise, Season) |>
  mutate(cumulative_franchise_g = cumsum(G)) |> # Step 1: Franchise-specific cumulative G
  ungroup() |>
  # overall cumulative G for player through that point in career
  arrange(PlayerId, Season) |>
  mutate(cumulative_career_g = cumsum(G)) |>
  group_by(PlayerId) |>
  arrange(PlayerId, age) |>
  mutate(
    # compute the highest G total with 1 franchise to that point in the player's career
    max_cume_frnch_g = cummax(cumulative_franchise_g)
  ) |>
  # compute seasonal totals by age. players traded midseason have multiple rows
  group_by(PlayerId, Name, age) |>
  mutate(
    WAR = sum(WAR),
    off = sum(Off),
    def = sum(Def),
    H = sum(H),
    HR = sum(HR),
    SB = sum(SB),
    num_asg = sum(asg),
    num_mvp_points = sum(num_mvp_points)
  ) |>
  replace_na(list(SB = 0)) |>
  distinct(PlayerId, Name, age, WAR, H, HR, SB, off, def, max_cume_frnch_g, career_midpoint_year, mlb_played_last, num_asg, num_mvp_points) |>
  # now, compute cumulative WAR & other stats through each age
  group_by(PlayerId, Name) |>
  arrange(age) |>
  mutate(
    num_seasons = n(),
    cumulative_war = cumsum(WAR),
    cumulative_off = cumsum(off),
    cumulative_def = cumsum(def),
    cumulative_mvp_pts = cumsum(num_mvp_points),
    cumulative_hr = cumsum(HR),
    cumulative_h = cumsum(H),
    cumulative_sb = cumsum(SB),
    cumulative_asg = cumsum(num_asg)
  ) |>
  # identify players elected to the Hall of Fame
  left_join(hof, by = "PlayerId") |>
  replace_na(list(hof = 0)) |>
  distinct() |> # getting duplicate rows for some reason. too lazy to fix it for real right now
  ungroup() |>
  mutate(
    considered_hof = if_else(hof_consideration_year - mlb_played_last < 6, FALSE, TRUE),
    hof = factor(hof, levels = c(1, 0)) # positive class prediction must be first level
  ) |>
  filter(!is.na(age)) |> # there are 80-ish NA values for 'age', all players in the late 1800s. get rid of 'em
  mutate(
    scandal_type = case_when(
      Name %in% c("Barry Bonds", "Roger Clemens", "Jose Canseco", "Rafael Palmeiro", "Jason Giambi", "Gary Sheffield", "Miguel Tejada", "Nelson Cruz", "Andy Pettitte", "Ryan Braun", "Manny Ramirez", "Alex Rodriguez", "Mark McGwire", "Sammy Sosa", "Robinson Cano", "Starling Marte", "Melky Cabrera", "David Ortiz", "Dee Gordon", "Bartolo Colon", "Fernando Tatis Jr.") ~ "PEDs",
      Name %in% c("Joe Jackson", "Eddie Cicotte", "Buck Weaver", "Chick Gandil", "Fred McMullin", "Swede Risberg", "Lefty Williams", "Joe Gedeon", "Pete Rose") ~ "gambling",
      Name %in% c("Carlos Beltran", "Jose Altuve", "Alex Bregman", "Alex Cora", "Carlos Correa", "George Springer", "Gaylord Perry") ~ "cheating",
      Name %in% c("Curt Schilling", "Lenny Dykstra", "Roberto Alomar") ~ "misconduct",
      Name %in% c("Marcell Ozuna", "Roberto Osuna", "Jose Reyes", "Aroldis Chapman", "Omar Vizquel", "Addison Russell", "Wander Franco", "Domingo German") ~ "domestic violence",
      TRUE ~ "none"
    ),

    # round all numeric columns to 1 decimal place for simplicity and ease of presentation
    across(where(is.numeric), round, 1)
  )
```

train the model and show information about it, such as a confusion matrix and AUPRC, and make predictions

```{r}
# make use of https://probably.tidymodels.org/articles/equivocal-zones.html ???

hof_split <-
  bat_data_full |>
  # train & test model only on players who have not played for 5 years
  filter(
    considered_hof,
    # thin out the dataset a bit. realistically you need to be somewhat of a consistent MLB regular before you're ACTUALLY considered. don't train on scrubs or short-termers.
    num_seasons >= 5
  ) |>
  # remove columns not needed for training
  select(-PlayerId, -Name, -H, -HR, -SB, -off, -def, -mlb_played_last, -num_asg, -num_seasons, -considered_hof, -WAR, -num_mvp_points, -cumulative_off, -cumulative_def) |>
  initial_split(strata = hof)

hof_train <- training(hof_split)
hof_test <- testing(hof_split)

# scale_pos_numerator <-
#   bat_data_full |> filter(considered_hof) |> distinct(PlayerId, hof) |> count(hof) |> filter(hof == 0) |> select(n) |> pluck(1)
#
# scale_pos <- scale_pos_numerator / (bat_data_full |> filter(considered_hof) |> distinct(PlayerId, hof) |> count(hof) |> filter(hof == 1) |> select(n) |> pluck(1))
#


# build a specification.
xgb_spec <-
  boost_tree(
    mode = "classification",
    trees = tune(),
    tree_depth = tune(),
    min_n = tune(),
    loss_reduction = tune(),
    sample_size = tune(),
    # scale_pos_weight = tune(),
    # mtry = tune(),
    learn_rate = tune(),
    stop_iter = tune()
  ) |>
  set_engine("xgboost", validation = 0.2) # validation proportion to use for early stop detection

xgb_grid <- grid_space_filling(
  trees(),
  tree_depth(),
  min_n(),
  loss_reduction(),
  # scale_pos_weight = c(52,55),
  sample_size = sample_prop(),
  stop_iter(range = c(10, 50)), # tune early stopping rounds
  # mtry(range = c(6, 32)),
  # finalize(mtry(), hof_train |> dplyr::select(-hof)),
  learn_rate(),
  size = 50
)

xgb_recipe <-
  recipe(hof ~ ., data = hof_train) |>
  step_dummy_multi_choice(scandal_type) |>
  step_smote(hof) # smote increases AUPRC, bal acc, and F1 by a meaningful amount.

xgb_wf <-
  workflow() |>
  add_model(xgb_spec) |>
  add_recipe(xgb_recipe)

all_cores <- parallel::detectCores(logical = FALSE)
cl <- makePSOCKcluster(all_cores)
registerDoParallel(cl)

# find the optimal values of tuning parameters using 10-fold cross validation
hof_folds <- vfold_cv(hof_train, strata = hof)

xgb_res <- tune_grid(
  xgb_wf,
  resamples = hof_folds,
  grid = xgb_grid,
  control = control_grid(
    save_pred = TRUE,
    verbose = TRUE
  ),
  metrics = metric_set(pr_auc),
)

# show how each parameter affects the model performance
xgb_res |>
  collect_metrics() |>
  filter(.metric == "pr_auc") |>
  dplyr::select(mean, min_n:sample_size) |>
  pivot_longer(min_n:sample_size,
    values_to = "value",
    names_to = "parameter"
  ) |>
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(alpha = 0.8, show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "PR_AUC")

best_auprc <- select_best(xgb_res, metric = "pr_auc")

final_xgb <- finalize_workflow(
  xgb_wf,
  best_auprc
)

# fit model to training set and evaluate on test set.
final_res <-
  last_fit(final_xgb, hof_split)

# extract final model and use it to predict HOF chances

hof_mdl <- final_res$.workflow[[1]]

# evaluate model using curves & area underneath it

predictions <-
  final_res |>
  collect_predictions()

# find optimal threshold for class predictions by maximizing the j index
# players with a predicted HOF probability above this point will be classified as HOF
optimal_threshold <-
  predictions |>
  threshold_perf(hof, .pred_1, thresholds = seq(0.1, 1, by = 0.0025)) |>
  filter(.metric == "j_index") |>
  arrange(desc(.estimate)) |>
  filter(row_number() == 1) |>
  dplyr::select(.threshold) |>
  as.numeric()


optimal_threshold <- optimal_threshold * 100

# not sure this is adding any value
# optimal_predictions <-
#   predictions |>
#   mutate(optimized_pred = factor(if_else(.pred_1 >= optimal_threshold, 1, 0),
#                                  levels = c(1,0)))

# TODO: predictions_optimized <-
# preds_new <- preds %>%
# mutate(new_class_pred = factor(ifelse(.pred_bad >= max_j_index_threshold, "bad", "good"),
#                                levels = c("bad", "good")))

# compute area under ROC using class probabilities
area_under_curve <-
  predictions |>
  pr_auc(truth = hof, .pred_1) |>
  dplyr::select(.estimate) |>
  as.numeric() |>
  round(2)

# draw  PR Curve using class probabilities
predictions |>
  pr_curve(truth = hof, .pred_1) |>
  ggplot(aes(recall, precision)) +
  geom_path() +
  coord_equal() +
  geom_hline(yintercept = 0, color = "blue", lty = "dashed") +
  ggtitle("Precision-Recall Curve, HOF Prediction Model",
    subtitle = glue("Area Under Curve: {area_under_curve}")
  )

ggsave("hof-mdl-pr-curve.png")

predictions |>
  conf_mat(truth = hof, estimate = .pred_class) |>
  pluck(1) |>
  as_tibble() |>
  ggplot(aes(Prediction, Truth)) +
  geom_tile(show.legend = FALSE) +
  geom_text(aes(label = n), colour = "white", alpha = 1) +
  ggtitle("Confusion Matrix, HOF Prediction Model")

ggsave("hof-mdl-confusion-matrix.png")


predictions |>
  f_meas(truth = hof, estimate = .pred_class)

predictions |>
  bal_accuracy(truth = hof, estimate = .pred_class)

# show the importance of each variable. remove 'X's from positions for readibility
final_xgb |>
  fit(data = hof_train) |>
  extract_fit_parsnip() |>
  vip::vi() |>
  mutate(Variable = str_replace_all(Variable, "X", "")) |>
  ggplot(aes(reorder(Variable, Importance), Importance)) +
  geom_col() +
  coord_flip() +
  labs(x = "") +
  ggtitle("Relative Predictor Importance, HOF Prediction Model")

ggsave("hof-mdl-variable-importance.png")

# Create an explainer using training data
explainer <- explain_tidymodels(hof_mdl,
  data = hof_train,
  y = as.numeric(hof_train$hof),

  # tell the explainer that a value of hof = 1 is a positive prediction
  predict_function_target_column = 1,
  verbose = FALSE
)
```


make predictions!!

``` {r}
# predict HOF chances for players who meet the following criteria:
# have not been considered for the HOF
# last played in the past 2 years (e.g. likely are still active) OR
# have at least 10 seasons in the majors (they are eligible at some point soon)
# this avoids predicting players like Brandon Webb and Josh Hamilton
# who are retired but didn't play 10 years so aren't eligible and will never be

year_threshold <- 2
last_season_played <- 2024

prep <-
  bat_data_full |>
  group_by(PlayerId) |>
  mutate(num_seasons_real = n_distinct(age)) |>
  ungroup() |>
  # remove guys not already in the Hall but who've played for at least 10 seasons or were active recently
  # remove those who've been considered, because they were in the training data
  filter(
    hof != 1,
    !considered_hof,
    (num_seasons_real >= 10 |
      num_seasons_real < 10 & mlb_played_last >= (last_season_played - year_threshold))
  ) |>
  # get most recent stats for all players
  group_by(PlayerId) |>
  filter(age == max(age)) |>
  ungroup()

final_predictions <- predict(hof_mdl, prep, type = "prob")

player_predictions <-
  bind_cols(prep, final_predictions) |>
  mutate(
    prob_hof = round(100 * .pred_1, 1),
    pred_hof = if_else(prob_hof >= optimal_threshold, TRUE, FALSE),
    war_per_year = round(cumulative_war / num_seasons_real, 1)
  ) |>
  select(Name, age, pred_hof, cumulative_war, war_per_year, cumulative_h, cumulative_hr, cumulative_mvps, scandal_type, career_midpoint_year, max_cume_frnch_g, cumulative_sb, cumulative_asg) |>
  arrange(desc(pred_hof), desc(war_per_year)) |>
  ungroup()

# View(player_predictions)

num_hof <- player_predictions |>
  count(pred_hof) |>
  filter(pred_hof) |>
  select(n) |>
  pull()

player_predictions |>
  group_by(pred_hof) |>
  slice_head(n = num_hof) |>
  select(Name, pred_hof, age, cumulative_war, cumulative_hr, cumulative_h, cumulative_sb, cumulative_mvps, cumulative_asg, scandal_type, war_per_year) |>
  arrange(desc(pred_hof), desc(war_per_year)) |>
  kbl() |>
  kable_styling()

player_predictions |>
  group_by(pred_hof) |>
  #  slice_head(n = num_hof) |>
  # select(Name, pred_hof, age, cumulative_war, cumulative_hr, cumulative_h, cumulative_sb, cumulative_mvps, scandal_type, war_per_year) |>
  arrange(desc(pred_hof), desc(war_per_year)) |>
  write_sheet("https://docs.google.com/spreadsheets/d/12uWa6dZaKnglJiXpE_fDZ5mCPrQ0rlQLrho6vlN6Jm8/edit?gid=0#gid=0", sheet = "Predictions")
```


'intercept' is the mean value of predictions in the dataset (?) so the starting point.


```{r}
# Compare 2 players of the same age, 1 predicted OF and the other not


# age 24
obvs <- "Bobby Witt Jr."
predict_parts(explainer = explainer, new_observation = player_predictions |> filter(Name == obvs)) |>
  arrange(contribution) |>
  plot()

obvs <- "Gabriel Moreno"
predict_parts(explainer = explainer, new_observation = player_predictions |> filter(Name == obvs)) |>
  arrange(contribution) |>
  plot()

# age 27

obvs <- "Yordan Alvarez"
predict_parts(explainer = explainer, new_observation = player_predictions |> filter(Name == obvs)) |>
  arrange(contribution) |>
  plot()

obvs <- "Jeremy Pena"
predict_parts(explainer = explainer, new_observation = player_predictions |> filter(Name == obvs)) |>
  arrange(contribution) |>
  plot()
```


```{r, fig.width=5, fig.height=7}
# TODO: think about how to show a player's overall percentage and how each of these add up. the base plotting function does that but they don't align the scales, so it makes it hard to compare.



compare <- c("Albert Pujols", "Yordan Alvarez", "Bryson Stott", "Jackson Merrill", "Jasson Dominguez")
foo <-
  compare |>
  purrr::map(get_player_explainer)

list_rbind(foo) |>
  select(Name, variable, contribution) |>
  filter(variable != "intercept" & variable != "prediction") |>
  ggplot(aes(contribution, variable)) +
  geom_col() +
  facet_grid(vars(Name), scales = "free_y") +
  labs(y = "")
```


```{r}
# Function to turn explanations into human-readable text
generate_english_explanation <- function(row_index, explainer, data_row) {
  # Ensure the row is in the correct format (single-row tibble)
  # data_row <- data_row |>
  #   mutate(across(everything(), ~ if (is.list(.)) unlist(.) else .))

  print(data_row)
  str(data_row)
  # Generate explanations for the row
  explanation <- predict_parts(explainer = explainer, new_observation = data_row)

  # Extract contributions and format as English text
  details <- explanation %>%
    mutate(
      sentence = case_when(
        variable == "(Intercept)" ~ glue("The base prediction starts at {round(contribution, 2)}."),
        TRUE ~ glue("The feature '{variable}' contributes {round(contribution, 2)} to the prediction.")
      )
    )

  # Combine into a single human-readable explanation
  glue(
    "For observation {row_index}, the prediction process can be described as:\n",
    paste(details$sentence, collapse = " "),
    "\nThe final predicted value is {round(sum(details$contribution), 2)}."
  )
}

# prepare the dataset used to generate the explainers

# Generate explanations for each row using purrr::map2_chr
english_explanations <- map2_chr(
  1:nrow(explainer_prep),
  split(explainer_prep, 1:nrow(explainer_prep)), # Split into single-row tibbles
  ~ generate_english_explanation(.x, explainer, .y)
)

# Print the explanations
cat(paste(english_explanations, collapse = "\n\n"))
```
