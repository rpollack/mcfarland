```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(caret)
library(broom)
library(glue)
library(rvest)
library(data.table)
library(twilio)
library(ggrepel)
library(styler)
#library(LearnBayes)

fgt <- theme(
  panel.background = element_rect(color = "lightgrey", fill = "white"),
  axis.title = element_text(family = "Lato"),
  axis.text = element_text(family = "Lato"),
  legend.title = element_text(family = "Lato"),
  legend.text = element_text(family = "Lato"),
  legend.background = element_rect(fill = "white"),
  legend.key = element_rect(fill = "white"),
  plot.title = element_text(family = "Lato"),
  panel.grid.major = element_line(size = .1, color = "lightgrey"),
  panel.grid.minor = element_line(size = 0),
  # strip.background = element_rect(fill = "#50ae26"),
  strip.text = element_text(family = "Lato")
)

fg_db <- dplyr::src_mysql(
  dbname = Sys.getenv("FG_DB"),
  host = Sys.getenv("FG_HOST"),
  user = Sys.getenv("FG_USER"),
  password = Sys.getenv("FG_PW")
)

TWILIO_SID <- Sys.getenv("TWILIO_SID")
TWILIO_TOKEN <- Sys.getenv("TWILIO_TOKEN")
twilio_number <- Sys.getenv("twilio_number")

send_message <- function(msg) {
  tw_send_message(from = twilio_number, to = "5123505107", body = msg)
}

train_and_assess_model <- function(algorithm, train_df, assess_df, eval_metric, player_type = NULL) {
  # train a model on a specified algorithm and assess it using the held-out test set
  # return a dynamically-assigned column name so we know which model made which assessment
  # save model to generic environment so it can be used for predictions

  mdl <- train(vote_share ~ .,
    data = train_df,
    method = algorithm,
    trControl = trainControl(
      method = "cv",
      number = 10,
      allowParallel = TRUE
    ),
    metric = eval_metric
  )

  label <- str_c("predict_", algorithm) # build the column name that will contain predictions the model makes

  # save model to global environment so it can be used later to make actual predictions
  model_name <- str_c(player_type, "hof_voting_model", algorithm, sep = "_")
  assign(model_name, mdl, envir = globalenv())

  # return prediction of model on assessment tibble
  as.numeric(predict(mdl, newdata = assess_df)) %>%
    as_tibble() %>%
    dplyr::select(!!label := value)
}

get_voting_results <- function(year) {
  # get player data and (if available) HOF voting results for a particular year
  url <- str_c("https://www.baseball-reference.com/awards/hof_", year, ".shtml")

  read_html(url) %>%
    html_nodes("table") %>%
    .[[1]] %>%
    html_table(header = FALSE) %>%
    as_tibble() %>%
    mutate(vote_year = as.numeric(year))
}

get_ped_scandal <- function(name) {
  # mark players who have a PED scandal asoscaited with them
  if_else(name %in% c(
    "Barry Bonds", "Roger Clemens", "Alex Rodriguez",
    "Gary Sheffield", "Rafael Palmeiro",
    "Sammy Sosa", "Mark McGwire", "Andy Pettite", "David Ortiz",
    "Manny Ramirez"
  ), 1, 0)
}

fix_name <- function(name) {
  # scrub player's name of weird characters that BB-Ref puts in their HOF voting data tables
  str_replace_all(str_replace(name, "y ", ""),
                  c(
                    "X-" = "",
                    "\\sHOF" = ""))
}
```


get raw data, clean up, and engineer some features

```{r}

year_to_predict <- 2019
num_years_to_train_on <- 15
first_training_year <- year_to_predict - num_years_to_train_on
last_training_year <- year_to_predict - 1

hof_voting_data <- seq(first_training_year, last_training_year) %>%
  map_df(get_voting_results)

data_clean <-
  hof_voting_data %>%
  dplyr::select(-X1, -X4,
    Name = X2, year_on_ballot = X3, vote_share = X5,
    bj_hof_monitor = X6, bj_hof_standards = X7, career_length = X8, career_rWAR = X9,
    best_war_years = X10, jaws = X11, jpos = X12, G_bat = X13, AB = X14, R = X15, H = X16, HR = X17, RBI = X18,
    SB = X19, BB = X20, BA = X21, OBP = X22, SLG = X23, OPS = X24, OPS_plus = X25,
    W = X26, L = X27, ERA = X28, ERA_plus = X29, WHIP = X30, G_pitch = X31, GS = X32, SV = X33, IP = X34,
    H_allowed = X35, HR_allowed = X36, BB_allowed = X37, SO = X38, position = X39
  ) %>%
  mutate(
    Name = fix_name(Name),
    year_on_ballot = as.numeric(str_extract(year_on_ballot, "[:digit:]{1,2}")),
    vote_share = as.double(str_extract(vote_share, "[:digit:]{1,3}.[:digit:]")),
    bj_hof_monitor = as.numeric(bj_hof_monitor),
    bj_hof_standards = as.numeric(bj_hof_standards),
    career_length = as.numeric(career_length),
    career_rWAR = as.double(career_rWAR),
    best_war_years = as.double(best_war_years),
    jaws = as.double(jaws),
    jpos = as.double(jpos),
    jaws_above_avg = jaws - jpos,
    G_bat = as.numeric(G_bat),
    AB = as.numeric(AB),
    R = as.numeric(R),
    H = as.numeric(H),
    HR = as.numeric(HR),
    RBI = as.numeric(RBI),
    SB = as.numeric(SB),
    BB = as.numeric(BB),
    BA = as.double(BA),
    OBP = as.double(OBP),
    SLG = as.double(SLG),
    OPS = as.double(OPS),
    OPS_plus = as.numeric(OPS_plus),
    W = as.numeric(W),
    L = as.numeric(L),
    ERA = as.double(ERA),
    ERA_plus = as.numeric(ERA_plus),
    WHIP = as.double(WHIP),
    G_pitch = as.numeric(G_pitch),
    GS = as.numeric(GS),
    SV = as.numeric(SV),
    IP = as.double(IP),
    H_allowed = as.numeric(H_allowed),
    HR_allowed = as.numeric(HR_allowed),
    BB_allowed = as.numeric(BB_allowed),
    SO = as.numeric(SO),
    position = as.numeric(str_extract(position, "[:digit:]")), # encode position as where they played the most often
    ped_scandal = map_dbl(Name, get_ped_scandal)
  ) %>%
  filter(!is.na(year_on_ballot)) %>% # remove spurious rows caused by BB-Ref table formatting
  group_by(Name) %>%
  arrange(Name, year_on_ballot) %>%
  mutate(
    prev_year_vote_share = lag(vote_share),
    prev_three_year_vote_share_trend = round((lag(vote_share) - lag(vote_share, 3)) / 3, 1)
  )
```

transform and clean data

specifically DO NOT select the X4 column 'vote total'.

leave all highly correlated predictors intact. i tried removing ones correlated below 0.9 and again at below 0.75. each time the models got worse.

```{r message=FALSE, warning=FALSE}

# TODO: add predictor: years left on ballot?
# TODO: select and pre-process data in one function, using different columns depending on whether the request is a batter, starter, or reliever .... and whether the "vote share" column is present (not really sure how to do this)
# TODO: Perhaps train models independently, allowing the use of (say) early_stopping_rounds for xgb, and other parameters for other algorithms
# TODO: Examine residual outliers & see if there is any trend I can identify
# TODO: See if major awards (batting titles, MVP's) affect results
# TODO: see if dist_from_3000_H and dist_from_500_HR affect results
# TODO: see if adding the player's primary position back in has any effect.

# best tune: XGBlinear, R^S of 0.9, RMSE Of 6.13, MAE of 3.6
# seed of 11 gets us here

batter_data <-
  data_clean %>%
  filter(position != 1) %>%
  dplyr::select(-position, Name, year_on_ballot, vote_share, prev_three_year_vote_share_trend, everything()) %>%
  ungroup() %>%
  dplyr::select(
    -W, -L, -ERA, -ERA_plus, -WHIP, -G_pitch, -GS, -SV, -IP, -H_allowed,
    -HR_allowed, -BB_allowed, -SO, -position, -career_length, -BB, -AB,
    -OBP, -SLG, -R, -OPS, -RBI, -HR, -OPS_plus, -jaws, -jpos, -bj_hof_standards, -G_bat
  )

# remove response variable & binary variable from cleaned data, preprocess remaining data & re-join
# to removed columns. preprocessing includes centering and scaling predictors as well as imputing missing values
# using k nearest neighbors
batter_data_pre <-
  batter_data %>%
  dplyr::select(-vote_share, -ped_scandal, -year_on_ballot, -vote_year)
batter_preprocess_params <- preProcess(batter_data_pre, method = c("center", "scale", "knnImpute"))
batter_data_clean_processed <- predict(batter_preprocess_params, batter_data_pre) %>%
  bind_cols(
    batter_data %>% dplyr::select(vote_share),
    batter_data %>% dplyr::select(ped_scandal),
    batter_data %>% dplyr::select(year_on_ballot),
    batter_data %>% dplyr::select(vote_year)
  )
```

# train and predict batter voting totals

```{r}

seed <-11
# seeds: 11, xgblinear with R^2 of 0.93 and RMSE of 7.5. 2019 predictions look good. 
# 12, xgbTree, with R^2 of 0.96 and RMSE of 6.5. 2019 predictions don't look great. Andruw Jones is at -5.8%
# 

# make training and test DF's. use seed to keep the splits the same between runs
set.seed(seed)
batter_test_df_rows <- createDataPartition(batter_data_clean_processed$vote_share, p = 0.3, list = FALSE)

batter_hof_test <-
  batter_data_clean_processed %>%
  dplyr::select(-Name) %>%
  filter(row_number() %in% batter_test_df_rows)

batter_hof_train <-
  batter_data_clean_processed %>%
  dplyr::select(-Name) %>%
  filter(!row_number() %in% batter_test_df_rows)

algorithms <- c("lm", "svmRadial", "xgbTree", "xgbLinear", "knn", "gbm")

# for each algorithm listed, train a model and assess it using the held-out test set,
# gather its predictions into a tibble, and compute residuals
batter_model_evaluation <-
  algorithms %>%
  map_dfc(train_and_assess_model, train_df = batter_hof_train, assess_df = batter_hof_test, eval_metric = "RMSE", player_type = "position_player") %>%
  as_tibble() %>%
  bind_cols(batter_hof_test) %>%
  dplyr::select(vote_share, contains("predict_")) %>%
  gather(model_type, predicted_vote_share, contains("predict_")) %>%
  dplyr::select(model_type, predicted_vote_share, vote_share) %>%
  mutate(residual = vote_share - predicted_vote_share)

# parameter_grid <-
#   expand.grid(
#     nrounds = c(40, 45, 50, 55, 60),
#     lambda = c(0, 0.05, 0.1, 0.15, 0.2, 0.25),
#     alpha = c(0, 0.01, 0.05, 0.1, 0.15, 0.2),
#     eta=c(0.1, 0.2, 0.3, 0.4, 0.5)
#   )
# hof_voting_model_xgbLinear_tuned <- train(vote_share ~ .,
#                                           data = batter_hof_train,
#                                           method = "xgbLinear",
#                                           trControl = trainControl(method = "cv",
#                                                                    number = 10,
#                                                                    allowParallel = TRUE),
#                                           tuneGrid = parameter_grid,
#                                           verbose = TRUE,
#                                           metric = "MAE")

batter_model_evaluation %>%
  ggplot(aes(vote_share, predicted_vote_share)) +
  geom_point() + geom_smooth(method = "lm") +
  fgt + facet_wrap(vars(model_type)) +
  expand_limits(x = 0, y = 0) +
  geom_abline(linetype = "dashed") + ggtitle("Model Evaluation: Position Player Voting %")

batter_model_evaluation %>%
  ggplot(aes(predicted_vote_share, residual)) + geom_point() +
  facet_wrap(vars(model_type)) + fgt +
  geom_hline(yintercept = 0, linetype = "dashed") + ggtitle("Model Evaluation: Residuals of Position Player Voting %")

batter_r_squared <-
  batter_model_evaluation %>%
  split(.$model_type) %>%
  map(~ lm(vote_share ~ predicted_vote_share, data = .)) %>%
  map(summary) %>%
  map_dbl("r.squared") %>%
  tidy() %>%
  dplyr::select(model_type = names, r_squared = x)

# display table of model evaluation statistics
batter_model_metrics <-
  batter_model_evaluation %>%
  group_by(model_type) %>%
  summarize(
    RMSE = RMSE(predicted_vote_share, vote_share),
    MAE = mean(abs(predicted_vote_share - vote_share))
  ) %>%
  inner_join(batter_r_squared, by = "model_type") %>%
  ungroup() %>%
  mutate(
    zr_squared = (r_squared - mean(r_squared)) / sd(r_squared),
    zRMSE = (RMSE - mean(RMSE)) / sd(RMSE),
    zMAE = (MAE - mean(MAE)) / sd(MAE),
    label = str_c(str_c(str_replace(model_type, "predict_", ""), ":"),
      "R^2:", str_c(round(r_squared, 2), ","),
      "RMSE:", round(RMSE, 1),
      sep = " "
    )
  ) %>%
  dplyr::select(`Model Type` = model_type, `R^2` = r_squared, RMSE, MAE, `zR^2` = zr_squared, zRMSE, zMAE, label)

ggplot(batter_model_metrics, aes(`zR^2`, zRMSE)) + geom_point() + fgt +
  geom_vline(xintercept = 0, linetype = "dashed") + geom_hline(yintercept = 0, linetype = "dashed") +
  geom_label_repel(aes(label = label)) +
  ggtitle("Evaluation Metrics of Models: Batter HOF Predictions") +
  xlim(-2, 2) + ylim(-2, 2) + labs(x = "zR^2")
```

position players: after selecting the best model, use it to predict future results

```{r}

url <- str_c("https://www.baseball-reference.com/awards/hof_", year_to_predict, ".shtml")

player_data <- read_html(url) %>%
  html_nodes("table") %>%
  .[[1]] %>%
  html_table(header = FALSE) %>%
  as_tibble() %>%
  mutate(vote_year = as.numeric(year_to_predict))
```

Transform and clean data, predict `r year_to_predict` voting share for position players

```{r message=FALSE, warning=FALSE}

# compute three-year vote share trend in the three years running up to the year we want to predict
# for example if we're predicting HOF voting in 2019, get vote shares from 2016 and 2018. use data points to compute slope of trend line
voting_trends <-
  data_clean %>%
  filter(vote_year %in% c(year_to_predict - 3, year_to_predict - 1)) %>%
  group_by(Name) %>%
  arrange(Name, vote_year) %>%
  mutate(
    prev_year_vote_share = vote_share,
    prev_three_year_vote_share_trend = round((vote_share) - lag(vote_share) / 3, 1),
    prev_three_year_vote_share_trend = replace_na(prev_three_year_vote_share_trend, 0)
  ) %>%
  filter(vote_year == max(vote_year)) %>%
  dplyr::select(Name, prev_year_vote_share, prev_three_year_vote_share_trend)

hof_predictions <-
  player_data %>%
  dplyr::select(-X1, -X4,
    Name = X2, year_on_ballot = X3, bj_hof_monitor = X5,
    bj_hof_standards = X6, career_length = X7, career_rWAR = X8, best_war_years = X9,
    jaws = X10, jpos = X11, G_bat = X12, AB = X13, R = X14, H = X15, HR = X16, RBI = X17,
    SB = X18, BB = X19, BA = X20, OBP = X21, SLG = X22, OPS = X23, OPS_plus = X24,
    W = X25, L = X26, ERA = X27, ERA_plus = X28, WHIP = X29, G_pitch = X30, GS = X31, SV = X32, IP = X33,
    H_allowed = X34, HR_allowed = X35, BB_allowed = X36, SO = X37, position = X38
  ) %>%
  mutate(
    Name = fix_name(Name),
    year_on_ballot = as.numeric(str_extract(year_on_ballot, "[:digit:]{1,2}")),
    bj_hof_monitor = as.numeric(bj_hof_monitor),
    bj_hof_standards = as.numeric(bj_hof_standards),
    career_length = as.numeric(career_length),
    career_rWAR = as.double(career_rWAR),
    best_war_years = as.double(best_war_years),
    jaws = as.double(jaws),
    jpos = as.double(jpos),
    jaws_above_avg = jaws - jpos,
    G_bat = as.numeric(G_bat),
    AB = as.numeric(AB),
    R = as.numeric(R),
    H = as.numeric(H),
    HR = as.numeric(HR),
    RBI = as.numeric(RBI),
    SB = as.numeric(SB),
    BB = as.numeric(BB),
    BA = as.double(BA),
    OBP = as.double(OBP),
    SLG = as.double(SLG),
    OPS = as.double(OPS),
    OPS_plus = as.numeric(OPS_plus),
    position = as.numeric(str_extract(position, "[:digit:]")),
    ped_scandal = map_dbl(Name, get_ped_scandal)
  ) %>%
  filter(!is.na(year_on_ballot))

batter_predictions <-
  hof_predictions %>%
  filter(position != "1") %>%
  left_join(voting_trends, by = "Name") %>%
  dplyr::select(
    -W, -L, -ERA, -ERA_plus, -WHIP, -G_pitch, -GS, -SV, -IP, -H_allowed,
    -HR_allowed, -BB_allowed, -SO, -position, -career_length, -BB, -AB, -OBP, -SLG, -R, -OPS, -RBI, -OPS_plus,
    -jaws, -jpos, -G_bat, -bj_hof_standards
  )

# preprocess 2019 HOF voting data using the same parameters identified earlier



predictions_pre <- batter_predictions %>%
  dplyr::select(-ped_scandal, -year_on_ballot, -vote_year)

predictions_processed <- predict(batter_preprocess_params, predictions_pre) %>%
  bind_cols(
    batter_predictions %>% dplyr::select(ped_scandal),
    batter_predictions %>% dplyr::select(year_on_ballot),
    batter_predictions %>% dplyr::select(vote_year)
  )
  


# batter_data_pre <-
#   batter_data %>%
#   dplyr::select(-vote_share, -ped_scandal, -year_on_ballot, -vote_year)
# batter_preprocess_params <- preProcess(batter_data_pre, method = c("center", "scale", "knnImpute"))
# batter_data_clean_processed <- predict(batter_preprocess_params, batter_data_pre) %>%
#   bind_cols(
#     batter_data %>% dplyr::select(vote_share),
#     batter_data %>% dplyr::select(ped_scandal),
#     batter_data %>% dplyr::select(year_on_ballot),
#     batter_data %>% dplyr::select(vote_year)
#   )


predict(position_player_hof_voting_model_xgbLinear, newdata = predictions_processed) %>%
  as_tibble() %>%
  dplyr::select(predicted_vote_share = value) %>%
  bind_cols(predictions_processed) %>%
  dplyr::select(Name, predicted_vote_share, everything()) %>%
  mutate(predicted_vote_share = round(predicted_vote_share, 1)) %>%
  arrange(desc(predicted_vote_share)) %>%
  left_join(voting_trends, by = "Name") %>%
  dplyr::select(Name, year_on_ballot, predicted_vote_share, previous_year_vote_share = prev_year_vote_share.y) %>%
  mutate(change = predicted_vote_share - previous_year_vote_share)

```


for batters: run bare xgboost algorithm to see if it gives better results than the caret-trained one.
for example the early_stopping_rounds arg could maybe prevent overfitting.

```{r}

# create xgboost-friendly matrices

batter_train_labels <- batter_hof_train$vote_share %>%
  as.matrix()
batter_train_matrix <-
  batter_hof_train %>%
  dplyr::select(-vote_share) %>%
  as.matrix()
batter_dtrain <- xgb.DMatrix(
  data = batter_train_matrix,
  label = batter_train_labels
)

params <- list(
  objective = "reg:linear",
  eval_metric = "rmse",
  booster = "gbtree"
)

# use 10-fold CV to determine the optimal number of iterations
batter_hof_xgb_mdl_params <- xgb.cv(
  params = params,
  data = batter_dtrain,
  nrounds = 500,
  nfold = 10,
  early_stopping_rounds = 10,
  print_every_n = 50,
  stratified = TRUE
)

num_rounds <- batter_hof_xgb_mdl_params$best_iteration

batter_hof_xgb_mdl <- xgb.train(
  params = params,
  data = batter_dtrain,
  nrounds = num_rounds
)

# construct xgboost-friendly test dataset, augment with model predictions, and evaluate
batter_test_labels <- batter_hof_test$vote_share %>%
  as.matrix()
batter_test_matrix <-
  batter_hof_test %>%
  dplyr::select(-vote_share) %>%
  as.matrix()

batter_dtest <- xgb.DMatrix(
  data = batter_test_matrix,
  label = batter_test_labels
)

xgb_predictions <-
  predict(batter_hof_xgb_mdl, newdata = batter_dtest) %>%
  as_tibble() %>%
  dplyr::select(predicted_vote_share = value) %>%
  bind_cols(batter_hof_test) %>%
  dplyr::select(vote_share, predicted_vote_share) %>%
  mutate(residual = vote_share - predicted_vote_share)

xgb_rmse <- RMSE(xgb_predictions$predicted_vote_share, xgb_predictions$vote_share)

xgb_r_squared <- round(summary(lm(xgb_predictions$predicted_vote_share ~ xgb_predictions$vote_share))$r.squared, 3)

ggplot(xgb_predictions, aes(vote_share, predicted_vote_share)) +
  geom_point() + geom_smooth(method = "lm")

ggplot(xgb_predictions, aes(vote_share, residual)) +
  geom_point()

# make 2019 predictions using model
data_2019 <- xgb.DMatrix(predictions_processed %>%
  dplyr::select(
    bj_hof_monitor,
    career_rWAR, best_war_years, H, SB, BA, jaws_above_avg, prev_year_vote_share,
    prev_three_year_vote_share_trend, ped_scandal, year_on_ballot, vote_year
  ) %>%
  as.matrix())

predict(batter_hof_xgb_mdl, newdata = data_2019) %>%
  as_tibble() %>%
  dplyr::select(predicted_vote_share = value) %>%
  bind_cols(predictions_processed %>% dplyr::select(Name, year_on_ballot)) %>%
  dplyr::select(Name, predicted_vote_share, everything()) %>%
  mutate(predicted_vote_share = round(predicted_vote_share, 1)) %>%
  arrange(desc(predicted_vote_share)) %>%
  left_join(voting_trends, by = "Name") %>%
  dplyr::select(Name, year_on_ballot, predicted_vote_share, previous_year_vote_share = prev_year_vote_share) %>%
  mutate(change = predicted_vote_share - previous_year_vote_share)
```



# now do it for starting pitchers!!

```{r}
# get number of cy youngs won by each pitcher
cy_young_winner_count <-
  read_csv("mlb season awards - cy_young_winners.csv") %>%
  gather(League, player_name, AL, NL) %>%
  group_by(player_name) %>%
  summarize(num_cy_youngs = n())

starter_hof_data <-
  data_clean %>%
  filter(
    position == 1,
    GS / G_pitch >= 0.5
  ) %>%
  dplyr::select(
    -position,
    Name,
    year_on_ballot,
    vote_share,
    prev_year_vote_share,
    everything()
  ) %>%
  left_join(cy_young_winner_count, by = c("Name" = "player_name")) %>%
  mutate(
    num_cy_youngs = replace_na(num_cy_youngs, 0),
    dist_from_300_w = W - 300,
    k_bb_ratio = SO / BB_allowed,
    dist_from_3000k = SO - 3000
  ) %>%
  dplyr::select(
    year_on_ballot,
    prev_year_vote_share,
    prev_three_year_vote_share_trend,
    bj_hof_monitor,
    ped_scandal,
    vote_year,
    vote_share
  ) %>%
  ungroup()

# pre-process relevant predictors by removing irrelevant ones, applying pre-processing, and re-adding irrelevant ones
starter_data_pre <-
  starter_hof_data %>%
  dplyr::select(-vote_share, -ped_scandal, -year_on_ballot, -vote_year)

pre_methods <- c("center", "scale", "knnImpute")
starter_preprocess_params <-
  preProcess(starter_data_pre, pre_methods)

starter_data_clean_processed <-
  predict(starter_preprocess_params, starter_data_pre) %>%
  bind_cols(
    starter_hof_data %>% dplyr::select(vote_share),
    starter_hof_data %>% dplyr::select(ped_scandal),
    starter_hof_data %>% dplyr::select(year_on_ballot),
    starter_hof_data %>% dplyr::select(vote_year)
  )

#set.seed(7)
starter_test_df_rows <-
  createDataPartition(starter_data_clean_processed$vote_share,
    p = 0.3,
    list = FALSE
  )

starter_hof_test <-
  starter_data_clean_processed %>%
  dplyr::select(-Name) %>%
  filter(row_number() %in% starter_test_df_rows)

starter_hof_train <-
  starter_data_clean_processed %>%
  dplyr::select(-Name) %>%
  filter(!row_number() %in% starter_test_df_rows)

algorithms <-
  c("lm", "svmRadial", "xgbTree", "xgbLinear", "knn", "gbm")

# for each algorithm listed, train a model and assess it using the held-out test set,
# gather its predictions into a tibble, and compute residuals
starter_model_evaluation <-
  algorithms %>%
  map_dfc(
    train_and_assess_model,
    starter_hof_train,
    starter_hof_test,
    "RMSE",
    "starter"
  ) %>%
  as_tibble() %>%
  bind_cols(starter_hof_test) %>%
  dplyr::select(vote_share, contains("predict_")) %>%
  gather(model_type, predicted_vote_share, contains("predict_")) %>%
  dplyr::select(model_type, predicted_vote_share, vote_share) %>%
  mutate(residual = vote_share - predicted_vote_share)

starter_model_evaluation %>%
  ggplot(aes(vote_share, predicted_vote_share)) +
  geom_point() + geom_smooth(method = "lm") +
  fgt + facet_wrap(vars(model_type)) +
  expand_limits(x = 0, y = 0) +
  geom_abline(linetype = "dashed") + ggtitle("Model Evaluation: Starter HOF Voting %")

starter_model_evaluation %>%
  ggplot(aes(predicted_vote_share, residual)) + geom_point() +
  facet_wrap(vars(model_type)) + fgt +
  geom_hline(yintercept = 0, linetype = "dashed") + ggtitle("Model Evaluation: Starter HOF Residuals")

starter_r_squared <-
  starter_model_evaluation %>%
  split(.$model_type) %>%
  map(~ lm(vote_share ~ predicted_vote_share, data = .)) %>%
  map(summary) %>%
  map_dbl("r.squared") %>%
  tidy() %>%
  dplyr::select(model_type = names, r_squared = x)

# display table of model evaluation statistics
starter_model_metrics <-
  starter_model_evaluation %>%
  group_by(model_type) %>%
  summarize(
    RMSE = RMSE(predicted_vote_share, vote_share),
    MAE = mean(abs(predicted_vote_share - vote_share))
  ) %>%
  inner_join(starter_r_squared, by = "model_type") %>%
  ungroup() %>%
  mutate(
    zr_squared = (r_squared - mean(r_squared)) / sd(r_squared),
    zRMSE = (RMSE - mean(RMSE)) / sd(RMSE),
    zMAE = (MAE - mean(MAE)) / sd(MAE),
    label = str_c(str_c(str_replace(model_type, "predict_", ""), ":"),
      "R^2:", str_c(round(r_squared, 2), ","),
      "RMSE:", round(RMSE, 1),
      sep = " "
    )
  ) %>%
  dplyr::select(`Model Type` = model_type, `R^2` = r_squared, RMSE, MAE, `zR^2` = zr_squared, zRMSE, zMAE, label)

ggplot(starter_model_metrics, aes(`zR^2`, zRMSE)) + geom_point() + fgt +
  geom_vline(xintercept = 0, linetype = "dashed") + geom_hline(yintercept = 0, linetype = "dashed") +
  geom_label_repel(aes(label = label)) +
  ggtitle("Evaluation Metrics of Models: Starter HOF Voting") +
  xlim(-2, 2) + ylim(-2, 2) + labs(x = "zR^2")

# best attempt so far: xgblinear, 0.9 R^2, 6.9 RMSE
```

make 2019 predictions using chosen model

```{r}
voting_trends <-
  data_clean %>%
  filter(vote_year %in% c(year_to_predict - 3, year_to_predict - 1)) %>%
  group_by(Name) %>%
  arrange(Name, vote_year) %>%
  mutate(
    prev_year_vote_share = vote_share,
    prev_three_year_vote_share_trend = round((vote_share) - lag(vote_share) / 3, 1)
  ) %>%
  filter(vote_year == max(vote_year)) %>%
  dplyr::select(Name, prev_year_vote_share, prev_three_year_vote_share_trend)

starter_hof_predictions <-
  player_data %>%
  dplyr::select(
    -X1,
    -X4,
    Name = X2,
    year_on_ballot = X3,
    bj_hof_monitor = X5,
    bj_hof_standards = X6,
    career_length = X7,
    career_rWAR = X8,
    best_war_years = X9,
    jaws = X10,
    jpos = X11,
    W = X25,
    L = X26,
    ERA = X27,
    ERA_plus = X28,
    WHIP = X29,
    G_pitch = X30,
    GS = X31,
    SV = X32,
    IP = X33,
    H_allowed = X34,
    HR_allowed = X35,
    BB_allowed = X36,
    SO = X37,
    position = X38
  ) %>%
  mutate(
    Name = fix_name(Name),
    year_on_ballot = as.numeric(str_extract(year_on_ballot, "[:digit:]{1,2}")),
    bj_hof_monitor = as.numeric(bj_hof_monitor),
    bj_hof_standards = as.numeric(bj_hof_standards),
    career_length = as.numeric(career_length),
    career_rWAR = as.double(career_rWAR),
    best_war_years = as.double(best_war_years),
    jaws = as.double(jaws),
    jpos = as.double(jpos),
    jaws_above_avg = jaws - jpos,
    W = as.numeric(W),
    L = as.numeric(L),
    ERA = as.double(ERA),
    ERA_plus = as.numeric(ERA_plus),
    WHIP = as.double(WHIP),
    G_pitch = as.numeric(G_pitch),
    GS = as.numeric(GS),
    SV = as.numeric(SV),
    IP = as.double(IP),
    H_allowed = as.numeric(H_allowed),
    HR_allowed = as.numeric(HR_allowed),
    BB_allowed = as.numeric(BB_allowed),
    SO = as.numeric(SO),
    position = as.numeric(str_extract(position, "[:digit:]")),
    ped_scandal = map_dbl(Name, get_ped_scandal)
  ) %>%
  filter(
    !is.na(year_on_ballot),
    position == 1,
    GS / G_pitch >= 0.5
  ) %>%
  left_join(voting_trends, by = "Name") %>%
  left_join(cy_young_winner_count, by = c("Name" = "player_name")) %>%
  mutate(
    num_cy_youngs = replace_na(num_cy_youngs, 0),
    dist_from_300_w = W - 300,
    k_bb_ratio = SO / BB_allowed,
    dist_from_3000k = SO - 3000,
    to_predict = 1 # this flag lets us know we want to predict these players. later on i join these players back to the main data set
    # to provide enough data points for knn inputation of NA values. to_predict lets us impute and then grab only the players
    # we want to predict
  ) %>%
  dplyr::select(
    Name,
    year_on_ballot,
    prev_year_vote_share,
    prev_three_year_vote_share_trend,
    bj_hof_monitor,
    ped_scandal,
    vote_year,
    to_predict
  ) %>%
  ungroup()


# in the above dataset there are too many rows with NA for knn imputation to work.
# so I have to:
# go back to the main dataset and mash it together to make it look like the one we're predicting
# use those values to impute the ones missing from the starters we want to predict
# predict vote share for the correct pitchers (e.g. not the ones we used to thicken the dataset for imputation). we do this with the to_predict column

bound_data <-
  data_clean %>%
  filter(
    position == 1,
    GS / G_pitch >= 0.5
  ) %>%
  left_join(cy_young_winner_count, by = c("Name" = "player_name")) %>%
  mutate(
    num_cy_youngs = replace_na(num_cy_youngs, 0),
    dist_from_300_w = W - 300,
    k_bb_ratio = SO / BB_allowed,
    dist_from_3000k = SO - 3000,
    to_predict = 0
  ) %>%
  dplyr::select(
   Name,
    year_on_ballot,
    prev_year_vote_share,
    prev_three_year_vote_share_trend,
    bj_hof_monitor,
    ped_scandal,
    vote_year,
    to_predict
  ) %>%
  bind_rows(starter_hof_predictions)

# pre-process 2019 starter data using parameters identified earlier: remove irrelevant data, pre-process remaining predictors, and add
# irrelevant data back in
starter_predictions_pre <-
  bound_data %>%
  dplyr::select(-ped_scandal, -year_on_ballot, -vote_year, -to_predict)
starter_predictions_processed <- predict(starter_preprocess_params, starter_predictions_pre) %>%
  bind_cols(
    bound_data %>% dplyr::select(ped_scandal),
    bound_data %>% dplyr::select(year_on_ballot),
    bound_data %>% dplyr::select(vote_year),
    bound_data %>% dplyr::select(to_predict)
  ) %>%
  filter(to_predict == 1) %>%
  dplyr::select(-to_predict)

predict(starter_hof_voting_model_xgbLinear, newdata = starter_predictions_processed) %>%
  as_tibble() %>%
  dplyr::select(predicted_vote_share = value) %>%
  bind_cols(starter_predictions_processed) %>%
  dplyr::select(Name, predicted_vote_share, everything()) %>%
  mutate(predicted_vote_share = round(predicted_vote_share, 1)) %>%
  arrange(desc(predicted_vote_share)) %>%
  left_join(voting_trends, by = "Name") %>%
  dplyr::select(Name, year_on_ballot, predicted_vote_share, previous_year_vote_share = prev_year_vote_share.y) %>%
  mutate(change = predicted_vote_share - previous_year_vote_share)
```


lastly, predict relievers

```{r}

reliever_hof_data <-
  data_clean %>%
  filter(
    position == 1,
    GS / G_pitch <= 0.5
  ) %>%
  dplyr::select(
    -position,
    Name,
    year_on_ballot,
    vote_share,
    prev_year_vote_share,
    everything()
  ) %>%
  dplyr::select(
    year_on_ballot,
    prev_year_vote_share,
    prev_three_year_vote_share_trend,
    bj_hof_monitor,
    bj_hof_standards,
    career_rWAR,
    best_war_years,
    jaws,
    W,
    L,
    ERA,
    ERA_plus,
    WHIP,
    IP,
    SO,
    SV,
    #k_bb_ratio,
    ped_scandal,
    vote_year,
    vote_share
  ) %>%
  ungroup()

reliever_data_pre <-
  reliever_hof_data %>%
  dplyr::select(-vote_share, -ped_scandal, -year_on_ballot, -vote_year)

pre_methods <- c("center", "scale", "knnImpute")
reliever_preprocess_params <-
  preProcess(reliever_data_pre, pre_methods)

reliever_data_clean_processed <-
  predict(reliever_preprocess_params, reliever_data_pre) %>%
  bind_cols(
    reliever_hof_data %>% dplyr::select(vote_share),
    reliever_hof_data %>% dplyr::select(ped_scandal),
    reliever_hof_data %>% dplyr::select(year_on_ballot),
    reliever_hof_data %>% dplyr::select(vote_year)
  )

set.seed(1)
reliever_test_df_rows <-
  createDataPartition(reliever_data_clean_processed$vote_share,
    p = 0.25,
    list = FALSE
  )

reliever_hof_test <-
  reliever_data_clean_processed %>%
  dplyr::select(-Name) %>%
  filter(row_number() %in% reliever_test_df_rows)

reliever_hof_train <-
  reliever_data_clean_processed %>%
  dplyr::select(-Name) %>%
  filter(!row_number() %in% reliever_test_df_rows)

algorithms <-
  c("xgbTree", "xgbLinear", "knn", "rf")

reliever_model_evaluation <-
  algorithms %>%
  map_dfc(
    train_and_assess_model,
    reliever_hof_train,
    reliever_hof_test,
    "RMSE"
  ) %>%
  as_tibble() %>%
  bind_cols(reliever_hof_test) %>%
  dplyr::select(vote_share, contains("predict_")) %>%
  gather(model_type, predicted_vote_share, contains("predict_")) %>%
  dplyr::select(model_type, predicted_vote_share, vote_share) %>%
  mutate(residual = vote_share - predicted_vote_share)

reliever_model_evaluation %>%
  ggplot(aes(vote_share, predicted_vote_share)) +
  geom_point() + geom_smooth(method = "lm") +
  fgt + facet_wrap(vars(model_type)) +
  expand_limits(x = 0, y = 0) +
  geom_abline(linetype = "dashed") + ggtitle("Model Evaluation: Reliever HOF Voting %")

reliever_model_evaluation %>%
  ggplot(aes(predicted_vote_share, residual)) + geom_point() +
  facet_wrap(vars(model_type)) + fgt +
  geom_hline(yintercept = 0, linetype = "dashed") + ggtitle("Model Evaluation: Reliever HOF Voting %")

reliever_r_squared <-
  reliever_model_evaluation %>%
  split(.$model_type) %>%
  map(~ lm(vote_share ~ predicted_vote_share, data = .)) %>%
  map(summary) %>%
  map_dbl("r.squared") %>%
  tidy() %>%
  dplyr::select(model_type = names, r_squared = x)

# display table of model evaluation statistics
reliever_model_metrics <-
  reliever_model_evaluation %>%
  group_by(model_type) %>%
  summarize(
    RMSE = RMSE(predicted_vote_share, vote_share),
    MAE = mean(abs(predicted_vote_share - vote_share))
  ) %>%
  inner_join(reliever_r_squared, by = "model_type") %>%
  ungroup() %>%
  mutate(
    zr_squared = (r_squared - mean(r_squared)) / sd(r_squared),
    zRMSE = (RMSE - mean(RMSE)) / sd(RMSE),
    zMAE = (MAE - mean(MAE)) / sd(MAE),
    label = str_c(str_c(str_replace(model_type, "predict_", ""), ":"),
      "R^2:", str_c(round(r_squared, 2), ","),
      "RMSE:", round(RMSE, 1),
      sep = " "
    )
  ) %>%
  dplyr::select(`Model Type` = model_type, `R^2` = r_squared, RMSE, MAE, `zR^2` = zr_squared, zRMSE, zMAE, label)

ggplot(reliever_model_metrics, aes(`zR^2`, zRMSE)) + geom_point() + fgt +
  geom_vline(xintercept = 0, linetype = "dashed") + geom_hline(yintercept = 0, linetype = "dashed") +
  geom_label_repel(aes(label = label)) +
  ggtitle("Evaluation Metrics of Models: Reliever HOF Voting %") +
  xlim(-2, 2) + ylim(-2, 2) + labs(x = "zR^2")

```

predict reliever vote share using best model

```{r}

```






