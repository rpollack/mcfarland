```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(caret)
library(broom)
library(glue)
library(rvest)
library(data.table)
library(ggrepel)
library(styler)
# library(LearnBayes)

fgt <- theme(
  panel.background = element_rect(color = "lightgrey", fill = "white"),
  axis.title = element_text(family = "Lato"),
  axis.text = element_text(family = "Lato"),
  legend.title = element_text(family = "Lato"),
  legend.text = element_text(family = "Lato"),
  legend.background = element_rect(fill = "white"),
  legend.key = element_rect(fill = "white"),
  plot.title = element_text(family = "Lato"),
  panel.grid.major = element_line(size = .1, color = "lightgrey"),
  panel.grid.minor = element_line(size = 0),
  # strip.background = element_rect(fill = "#50ae26"),
  strip.text = element_text(family = "Lato")
)

fg_db <- dplyr::src_mysql(
  dbname = Sys.getenv("FG_DB"),
  host = Sys.getenv("FG_HOST"),
  user = Sys.getenv("FG_USER"),
  password = Sys.getenv("FG_PW")
)

train_and_assess_model <- function(algorithm, train_df, assess_df, eval_metric, player_type = NULL) {
  # train a model on a specified algorithm and assess it using the held-out test set
  # return a dynamically-assigned column name so we know which model made which assessment
  # save model to generic environment so it can be used for predictions

  mdl <- train(vote_share ~ .,
    data = train_df,
    method = algorithm,
    trControl = trainControl(
      method = "cv",
      number = 10,
      allowParallel = TRUE
    ),
    metric = eval_metric,
    tuneLength = 5
    
  )

  label <- str_c("predict_", algorithm) # build the column name that will contain predictions the model makes

  # save model to global environment so it can be used later to make actual predictions
  model_name <- str_c(player_type, "hof_voting_model", algorithm, sep = "_")
  assign(model_name, mdl, envir = globalenv())

  # return prediction of model on assessment tibble
  as.numeric(predict(mdl, newdata = assess_df)) %>%
    as_tibble() %>%
    dplyr::select(!!label := value)
}

get_voting_results <- function(year) {
  # get player data and (if available) HOF voting results for a particular year
  url <- str_c("https://www.baseball-reference.com/awards/hof_", year, ".shtml")

  read_html(url) %>%
    html_nodes("table") %>%
    .[[1]] %>%
    html_table(header = FALSE) %>%
    as_tibble() %>%
    mutate(vote_year = as.numeric(year))
}

set_narrative <- function(name) {
  # rank players on a scale of -1 (strongly negative narrative) to 1 (strongly positive narrative)
  # to account for the fact that HOF cases are about more than just stats
  case_when(
    
    # strong negative narrative
    name %in% c(
    "Barry Bonds", "Roger Clemens", "Alex Rodriguez",
    "Gary Sheffield", "Rafael Palmeiro", "Sammy Sosa", "Mark McGwire", "Manny Ramirez", "Pete Rose",
    "Jose Canseco", "Ken Caminiti") ~ -1,
    
    # mild negative narrative. includes 'nicer' PED cases , guys who were jerks, and guys who tend to get overlooked, like: 
    # guys who spent significant time in Coors Field, really good all-around players, and those
    # who are overshadowed by a peer
    name %in% c("Andy Pettite", "David Ortiz", "Jeff Kent", "Todd Helton", "Larry Walker", "Dante Bichette",
                "Kenny Lofton", "Andruw Jones", "Scott Rolen", "Jim Edmonds", "Tim Raines", "Bert Blyleven",
                "Ron Santo", "Billy Wagner", "Bobby Grich", "Alan Trammell", "Lou Whitaker",
                "Curt Schilling", "Kevin Brown") ~ -0.5,
    
    # mild positive narrative (you can call these guys "overrated")
    name %in% c("Jim Rice", "Andre Dawson", "Jack Morris", "Bruce Sutter", "Jorge Posada", "Omar Vizquel", "Trevor Hoffman") ~ 0.5,
    
    #strong positive narrative; something about their career and/or character strongly transcends their stats
    name %in% c("Roy Halladay", "Mariano Rivera", "Kirby Puckett", "Bill Mazeroski",
                "Juan Marichal", "Bob Feller", "Vic Willis", "Don Drysdale", "Red Ruffing", "Jim Bunning", "John Smoltz",
                "Don Sutton", "Sandy Koufax") ~ 1,
    
    # everyone else gets no discernable narrative
    TRUE ~ 0
  )
}

fix_name <- function(name) {
  # scrub player's name of weird characters that BB-Ref puts in their HOF voting data tables
  str_replace_all(
    str_replace(name, "y ", ""),
    c(
      "X-" = "",
      "\\sHOF" = ""
    )
  )
}
```


get data, clean up, and engineer some features. 
```{r}


year_to_predict <- 2019
first_training_year <- 1966
last_training_year <- year_to_predict - 1

# get past voting data that will be used to train and test models
hof_voting_data_historical <- seq(first_training_year, last_training_year) %>%
  map_df(get_voting_results)

hof_voting_data_historical_clean <-
  hof_voting_data_historical %>%
  dplyr::select(
    Name = X2, year_on_ballot = X3, vote_share = X5,
    bj_hof_monitor = X6, bj_hof_standards = X7, career_length = X8, career_rWAR = X9,
    best_war_years = X10, jaws = X11, jpos = X12, G_bat = X13, AB = X14, R = X15, H = X16, HR = X17, RBI = X18,
    SB = X19, BB = X20, BA = X21, OBP = X22, SLG = X23, OPS = X24, OPS_plus = X25,
    W = X26, L = X27, ERA = X28, ERA_plus = X29, WHIP = X30, G_pitch = X31, GS = X32, SV = X33, IP = X34,
    H_allowed = X35, HR_allowed = X36, BB_allowed = X37, SO = X38, position = X39, vote_year
  ) %>%
  mutate(
    Name = fix_name(Name),
    year_on_ballot = as.numeric(str_extract(year_on_ballot, "[:digit:]{1,2}")),
    vote_share = as.double(str_extract(vote_share, "[:digit:]{1,3}.[:digit:]")),
    bj_hof_monitor = as.numeric(bj_hof_monitor),
    bj_hof_standards = as.numeric(bj_hof_standards),
    career_length = as.numeric(career_length),
    career_rWAR = as.double(career_rWAR),
    best_war_years = as.double(best_war_years),
    jaws = as.numeric(jaws),
    jpos = as.numeric(jpos),
    jaws_plus = 100 * (jaws / jpos),
    G_bat = as.numeric(G_bat),
    AB = as.numeric(AB),
    R = as.numeric(R),
    H = as.numeric(H),
    HR = as.numeric(HR),
    RBI = as.numeric(RBI),
    SB = as.numeric(SB),
    BB = as.numeric(BB),
    BA = as.double(BA),
    OBP = as.double(OBP),
    SLG = as.double(SLG),
    OPS = as.double(OPS),
    OPS_plus = as.numeric(OPS_plus),
    W = as.numeric(W),
    L = as.numeric(L),
    ERA = as.double(ERA),
    ERA_plus = as.numeric(ERA_plus),
    WHIP = as.double(WHIP),
    G_pitch = as.numeric(G_pitch),
    GS = as.numeric(GS),
    SV = as.numeric(SV),
    IP = as.double(IP),
    H_allowed = as.numeric(H_allowed),
    HR_allowed = as.numeric(HR_allowed),
    BB_allowed = as.numeric(BB_allowed),
    SO = as.numeric(SO),
    position = factor(str_extract(position, "[:digit:]")), # encode position as where they played the most often
    narrative_score = set_narrative(Name)
  ) %>%
  filter(!is.na(year_on_ballot)) %>% # remove spurious rows caused by BB-Ref table formatting
  group_by(Name) %>%
  arrange(Name, year_on_ballot) %>%
  mutate(
    prev_year_vote_share = lag(vote_share),
    prev_three_year_vote_share_trend = round((lag(vote_share) - lag(vote_share, 3)) / 3, 1)
  )


# get data for the year we want to predict, to to assess the final model
url <- str_c("https://www.baseball-reference.com/awards/hof_", year_to_predict, ".shtml")

hof_voting_data_future <- read_html(url) %>%
  html_nodes("table") %>%
  .[[1]] %>%
  html_table(header = FALSE) %>%
  as_tibble() %>%
  mutate(vote_year = as.numeric(year_to_predict))

hof_voting_data_future_clean <-
  hof_voting_data_future %>%
  dplyr::select(
    Name = X2,
    year_on_ballot = X3,
    bj_hof_monitor = X5,
    # bj_hof_standards = X6,
    # career_length = X7,
    # career_rWAR = X8,
    best_war_years = X9,
    jaws = X10,
    jpos = X11,
    # G_bat = X12,
    # AB = X13,
    # R = X14,
    # H = X15,
    # HR = X16,
    # RBI = X17,
    # SB = X18,
    # BB = X19,
    # BA = X20,
    # OBP = X21,
    # SLG = X22,
    # OPS = X23,
    # OPS_plus = X24,
    W = X25,
    # L = X26,
    ERA = X27,
    # ERA_plus = X28,
    # WHIP = X29,
    G_pitch = X30,
    GS = X31,
    SV = X32,
    # IP = X33,
    # H_allowed = X34,
    # HR_allowed = X35,
    # BB_allowed = X36,
    SO = X37,
    position = X38,
    vote_year
  ) %>%
  mutate(
    Name = fix_name(Name),
    year_on_ballot = as.numeric(str_extract(year_on_ballot, "[:digit:]{1,2}")),
    bj_hof_monitor = as.numeric(bj_hof_monitor),
    best_war_years = as.numeric(best_war_years),
    position = factor(str_extract(position, "[:digit:]")),
    SV = as.numeric(SV),
    narrative_score = set_narrative(Name),
    jaws = as.numeric(jaws),
    jpos = as.numeric(jpos),
    jaws_plus = 100 * (jaws / jpos),
    G_pitch = as.numeric(G_pitch),
    GS = as.numeric(GS),
    SV = as.numeric(SV),
    SO = as.numeric(SO),
    W = as.numeric(W),
    ERA = as.numeric(ERA)
  ) %>%
  filter(!is.na(year_on_ballot))
```

Explore and visualize data 

```{r}
hof_voting_data_historical_clean %>%
  gather(metric, value, bj_hof_standards, bj_hof_monitor, jaws_plus) %>%
  dplyr::select(Name, year_on_ballot, metric, value, vote_share) %>%
  group_by(Name) %>%
  filter(year_on_ballot == max(year_on_ballot)) %>%
  rename(num_years_on_ballot = year_on_ballot) %>%
  ggplot(aes(num_years_on_ballot, value, color = vote_share)) +
  geom_point() + facet_wrap(vars(metric))

# free scales on the y-axis
```



Create preprocessed training, validation, and test datasets for position players, starters, and relievers
They each need different datasets because they will have different predictors & those predictors will be scaled differently

```{r message=FALSE, warning=FALSE}

# TODO: add predictor: years left on ballot?
# TODO: select and pre-process data in one function, using different columns depending on whether the request is a batter, starter, or reliever .... and whether the "vote share" column is present (not really sure how to do this)
# TODO: Perhaps train models independently, allowing the use of (say) early_stopping_rounds for xgb, and other parameters for other algorithms
# TODO: Examine residual outliers & see if there is any trend I can identify
# TODO: See if major awards (batting titles, MVP's) affect results
# TODO: see if dist_from_3000_H and dist_from_500_HR affect results
# TODO: see if adding the player's primary position back in has any effect.

# POSITION PLAYERS
batter_data <-
  hof_voting_data_historical_clean %>%
  filter(position != 1) %>%
  ungroup() %>%
  dplyr::select(Name, year_on_ballot, vote_year, prev_year_vote_share, prev_three_year_vote_share_trend, narrative_score, bj_hof_monitor, vote_share)

# remove response variable & binary variable from cleaned data, preprocess remaining data & re-join
# to removed columns. preprocessing includes centering and scaling predictors as well as imputing missing values
# using k nearest neighbors
batter_data_pre <-
  batter_data %>%
  dplyr::select(-vote_share, -year_on_ballot, -vote_year)
batter_preprocess_params <- preProcess(batter_data_pre, method = c("center", "scale", "knnImpute"))
batter_data_preprocessed <- predict(batter_preprocess_params, batter_data_pre) %>%
  bind_cols(
    batter_data %>% dplyr::select(vote_share, year_on_ballot, vote_year)
  )

batter_test_df_rows <- createDataPartition(batter_data_preprocessed$vote_share, p = 0.25, list = FALSE)

batter_hof_test <-
  batter_data_preprocessed %>%
  dplyr::select(-Name) %>%
  filter(row_number() %in% batter_test_df_rows)

batter_hof_train <-
  batter_data_preprocessed %>%
  dplyr::select(-Name) %>%
  filter(!row_number() %in% batter_test_df_rows)

# engineer, clean, and process data for the year we want to predict
voting_trends <-
  hof_voting_data_historical_clean %>%
  filter(vote_year %in% c(year_to_predict - 3, year_to_predict - 1)) %>%
  group_by(Name) %>%
  arrange(Name, vote_year) %>%
  mutate(
    prev_year_vote_share = vote_share,
    prev_three_year_vote_share_trend = round((vote_share) - lag(vote_share) / 3, 1),
    prev_three_year_vote_share_trend = replace_na(prev_three_year_vote_share_trend, 0)
  ) %>%
  filter(vote_year == max(vote_year)) %>%
  dplyr::select(Name, prev_year_vote_share, prev_three_year_vote_share_trend)

batter_voting_future <-
  hof_voting_data_future_clean %>%
  filter(position != "1") %>%
  left_join(voting_trends, by = "Name") %>%
  dplyr::select(Name, year_on_ballot, vote_year, prev_year_vote_share, prev_three_year_vote_share_trend, narrative_score, bj_hof_monitor)

# preprocess 2019 HOF voting data using the same parameters identified earlier
batter_voting_future_pre <- 
  batter_voting_future %>%
  dplyr::select(-year_on_ballot, -vote_year)
batter_voting_future_preprocessed <- predict(batter_preprocess_params, batter_voting_future_pre) %>%
  bind_cols(
    batter_voting_future %>% dplyr::select(year_on_ballot, vote_year)
  )
######################## STARTING PITCHERS: prepare training and validation datasets ###########

cy_young_winner_count <-
  read_csv("mlb season awards - cy_young_winners.csv") %>%
  gather(League, player_name, AL, NL) %>%
  group_by(player_name) %>%
  summarize(num_cy_youngs = n())

starter_hof_data <-
  hof_voting_data_historical_clean %>%
  filter(
    position == 1,
    GS / G_pitch >= 0.5
  ) %>%
  dplyr::select(
    Name,
    year_on_ballot,
    vote_share,
    prev_year_vote_share,
    everything()
  ) %>%
  left_join(cy_young_winner_count, by = c("Name" = "player_name")) %>% # TODO: see if this has any effect on predictions. is currently unused
  mutate(
    num_cy_youngs = replace_na(num_cy_youngs, 0),
    dist_from_300_w = W - 300,
    k_bb_ratio = SO / BB_allowed,
    dist_from_3000k = SO - 3000
  ) %>%
  dplyr::select(
    year_on_ballot,
    prev_year_vote_share,
    prev_three_year_vote_share_trend,
    bj_hof_monitor,
    narrative_score,
    vote_year,
    ERA,
    SO,
    vote_share
  ) %>%
  ungroup()

# pre-process relevant predictors by removing irrelevant ones, applying pre-processing, and re-adding irrelevant ones
starter_data_pre <-
  starter_hof_data %>%
  dplyr::select(-vote_share, -year_on_ballot, -vote_year)

pre_methods <- c("center", "scale", "knnImpute")
starter_preprocess_params <-
  preProcess(starter_data_pre, pre_methods)

starter_data_preprocessed <-
  predict(starter_preprocess_params, starter_data_pre) %>%
  bind_cols(
    starter_hof_data %>% dplyr::select(vote_share, year_on_ballot, vote_year)
  )

starter_test_df_rows <-
  createDataPartition(starter_data_preprocessed$vote_share,
    p = 0.25,
    list = FALSE
  )

starter_hof_test <-
  starter_data_preprocessed %>%
  dplyr::select(-Name) %>%
  filter(row_number() %in% starter_test_df_rows)

starter_hof_train <-
  starter_data_preprocessed %>%
  dplyr::select(-Name) %>%
  filter(!row_number() %in% starter_test_df_rows)

# STARTING PITCHERS: Prepare data used to test model
starter_voting_future <-
  hof_voting_data_future_clean %>%
  filter(
    position == 1,
    GS / G_pitch >= 0.5
  ) %>%
  left_join(voting_trends, by = "Name") %>%
  left_join(cy_young_winner_count, by = c("Name" = "player_name")) %>%
  mutate(
    num_cy_youngs = replace_na(num_cy_youngs, 0),
    dist_from_300_w = W - 300,
    # k_bb_ratio = SO / BB_allowed,
    dist_from_3000k = SO - 3000,
    to_predict = 1 # this flag lets us know we want to predict these players. later on i join these players back to the main data set
    # to provide enough data points for knn inputation of NA values. to_predict lets us impute and then grab only the players
    # we want to predict
  ) %>%
  dplyr::select(
    Name,
    year_on_ballot,
    prev_year_vote_share,
    prev_three_year_vote_share_trend,
    bj_hof_monitor,
    narrative_score,
    vote_year,
    ERA,
    SO,
    to_predict
  ) %>%
  ungroup()

# in the above dataset there are too many rows with NA for knn imputation to work.
# so I have to:
# go back to the main dataset and mash it together to make it look like the one we're predicting
# use those values to impute the ones missing from the starters we want to predict
# predict vote share for the correct pitchers (e.g. not the ones we used to thicken the dataset for imputation). we do this with the to_predict column

starter_data_padded <-
  hof_voting_data_historical_clean %>%
  filter(
    position == 1,
    GS / G_pitch >= 0.5
  ) %>%
  left_join(cy_young_winner_count, by = c("Name" = "player_name")) %>%
  mutate(
    num_cy_youngs = replace_na(num_cy_youngs, 0),
    dist_from_300_w = W - 300,
    k_bb_ratio = SO / BB_allowed,
    dist_from_3000k = SO - 3000,
    to_predict = 0
  ) %>%
  dplyr::select(
    Name,
    year_on_ballot,
    prev_year_vote_share,
    prev_three_year_vote_share_trend,
    bj_hof_monitor,
    narrative_score,
    vote_year,
    ERA,
    SO,
    to_predict
  ) %>%
  bind_rows(starter_voting_future) %>% 
  ungroup()

# pre-process 2019 starter data using parameters identified earlier: remove irrelevant data, pre-process remaining predictors, and add
# irrelevant data back in
starter_predictions_pre <-
  starter_data_padded %>%
  dplyr::select(-year_on_ballot, -vote_year, -to_predict)
starter_voting_future_preprocessed <- predict(starter_preprocess_params, starter_predictions_pre) %>%
  bind_cols(
    starter_data_padded %>% dplyr::select(year_on_ballot, vote_year, to_predict)
  ) %>%
  filter(to_predict == 1) %>%
  dplyr::select(-to_predict)

# RELIEF PITCHERS: prepare training and validation data

# get predictors for relief pitchers.
# Bill James' HOF monitor doesn't account for relievers b/c it's position-agnostic
# so I use JAWS+ (JAWS relative to average at position) to separate the wheat from the chaff
reliever_hof_data <-
  hof_voting_data_historical_clean %>%
  filter(
    position == 1,
    GS / G_pitch <= 0.5
  ) %>%
  dplyr::select(
    Name,
    year_on_ballot,
    vote_share,
    vote_year,
    prev_year_vote_share,
    prev_three_year_vote_share_trend,
    jaws,
    jpos,
    SV,
    narrative_score
  ) %>%
  group_by(Name) %>%
  mutate(jaws_plus = round(100 * (jaws / jpos)), 0) %>%
  dplyr::select(-jaws, -jpos) %>%
  ungroup()

# pre-process data. 
reliever_data_pre <-
  reliever_hof_data %>%
  dplyr::select(-vote_share, -year_on_ballot, -vote_year)
pre_methods <- c("center", "scale", "knnImpute")
reliever_preprocess_params <- preProcess(reliever_data_pre, pre_methods)
reliever_data_clean_processed <-
  predict(reliever_preprocess_params, reliever_data_pre) %>%
  bind_cols(
    reliever_hof_data %>% dplyr::select(vote_share, year_on_ballot, vote_year)
  )

reliever_test_df_rows <-
  createDataPartition(reliever_data_clean_processed$vote_share,
    p = 0.25,
    list = FALSE
  )

reliever_hof_test <-
  reliever_data_clean_processed %>%
  dplyr::select(-Name) %>%
  filter(row_number() %in% reliever_test_df_rows)

reliever_hof_train <-
  reliever_data_clean_processed %>%
  dplyr::select(-Name) %>%
  filter(!row_number() %in% reliever_test_df_rows)

# RELIEF PITCHERS: Prepare data used to test model

reliever_hof_predictions <-
  hof_voting_data_future_clean %>%
  filter(
    position == 1,
    GS / G_pitch <= 0.5
  ) %>%
  left_join(voting_trends, by = "Name") %>%
  group_by(Name) %>%
  mutate(jaws_plus = round(100 * (jaws / jpos)), 0) %>%
  dplyr::select(
    Name,
    prev_year_vote_share,
    prev_three_year_vote_share_trend,
    SV,
    jaws_plus,
    narrative_score,
    year_on_ballot,
    vote_year
  ) %>%
  ungroup()

reliever_predictions_pre <-
  reliever_hof_predictions %>%
  dplyr::select(-narrative_score, -year_on_ballot, -vote_year)
reliever_predictions_processed <- predict(reliever_preprocess_params, reliever_predictions_pre) %>%
  bind_cols(
    reliever_hof_predictions %>% dplyr::select(year_on_ballot, vote_year)
  )
```

# train and predict batter voting totals

```{r}

algorithms <- c("lm", "svmRadial", "xgbTree", "xgbLinear", "knn", "gbm")

# for each algorithm listed, train a model and assess it using the held-out test set,
# gather its predictions into a tibble, and compute residuals
batter_model_evaluation <-
  algorithms %>%
  map_dfc(
    train_and_assess_model,
    batter_hof_train,
    batter_hof_test,
    "RMSE",
    "position_player"
  ) %>%
  as_tibble() %>%
  bind_cols(batter_hof_test) %>%
  dplyr::select(vote_share, contains("predict_")) %>%
  gather(model_type, predicted_vote_share, contains("predict_")) %>%
  dplyr::select(model_type, predicted_vote_share, vote_share) %>%
  mutate(residual = vote_share - predicted_vote_share)

# parameter_grid <-
#   expand.grid(
#     nrounds = c(40, 45, 50, 55, 60),
#     lambda = c(0, 0.05, 0.1, 0.15, 0.2, 0.25),
#     alpha = c(0, 0.01, 0.05, 0.1, 0.15, 0.2),
#     eta=c(0.1, 0.2, 0.3, 0.4, 0.5)
#   )
# hof_voting_model_xgbLinear_tuned <- train(vote_share ~ .,
#                                           data = batter_hof_train,
#                                           method = "xgbLinear",
#                                           trControl = trainControl(method = "cv",
#                                                                    number = 10,
#                                                                    allowParallel = TRUE),
#                                           tuneGrid = parameter_grid,
#                                           verbose = TRUE,
#                                           metric = "MAE")

batter_model_evaluation %>%
  ggplot(aes(vote_share, predicted_vote_share)) +
  geom_point() + geom_smooth(method = "lm") +
  fgt + facet_wrap(vars(model_type)) +
  expand_limits(x = 0, y = 0) +
  geom_abline(linetype = "dashed") + ggtitle("Model Evaluation: Position Player Voting %")

batter_model_evaluation %>%
  ggplot(aes(predicted_vote_share, residual)) + geom_point() +
  facet_wrap(vars(model_type)) + fgt +
  geom_hline(yintercept = 0, linetype = "dashed") + ggtitle("Model Evaluation: Residuals of Position Player Voting %")

batter_r_squared <-
  batter_model_evaluation %>%
  split(.$model_type) %>%
  map(~ lm(vote_share ~ predicted_vote_share, data = .)) %>%
  map(summary) %>%
  map_dbl("r.squared") %>%
  tidy() %>%
  dplyr::select(model_type = names, r_squared = x)

# display table of model evaluation statistics
batter_model_metrics <-
  batter_model_evaluation %>%
  group_by(model_type) %>%
  summarize(
    RMSE = RMSE(predicted_vote_share, vote_share),
    MAE = mean(abs(predicted_vote_share - vote_share))
  ) %>%
  inner_join(batter_r_squared, by = "model_type") %>%
  ungroup() %>%
  mutate(
    zr_squared = (r_squared - mean(r_squared)) / sd(r_squared),
    zRMSE = (RMSE - mean(RMSE)) / sd(RMSE),
    zMAE = (MAE - mean(MAE)) / sd(MAE),
    label = str_c(str_c(str_replace(model_type, "predict_", ""), ":"),
      "R^2:", str_c(round(r_squared, 2), ","),
      "RMSE:", round(RMSE, 1),
      sep = " "
    )
  ) %>%
  dplyr::select(`Model Type` = model_type, `R^2` = r_squared, RMSE, MAE, `zR^2` = zr_squared, zRMSE, zMAE, label)

ggplot(batter_model_metrics, aes(`zR^2`, zRMSE)) + geom_point() + fgt +
  geom_vline(xintercept = 0, linetype = "dashed") + geom_hline(yintercept = 0, linetype = "dashed") +
  geom_label_repel(aes(label = label)) +
  ggtitle("Evaluation Metrics of Models: Batter HOF Predictions") +
  xlim(-2, 2) + ylim(-2, 2) + labs(x = "zR^2")
```

Transform and clean data, predict `r year_to_predict` voting share for position players

```{r message=FALSE, warning=FALSE}


predict(position_player_hof_voting_model_gbm, newdata = batter_voting_future_preprocessed) %>%
  as_tibble() %>%
  dplyr::select(predicted_vote_share = value) %>%
  bind_cols(batter_voting_future_preprocessed) %>%
  dplyr::select(Name, predicted_vote_share, everything()) %>%
  mutate(predicted_vote_share = round(predicted_vote_share, 1)) %>%
  arrange(desc(predicted_vote_share)) %>%
  left_join(voting_trends, by = "Name") %>%
  dplyr::select(Name, year_on_ballot, predicted_vote_share, previous_year_vote_share = prev_year_vote_share.y) %>%
  mutate(change = predicted_vote_share - previous_year_vote_share)
```


for batters: run bare xgboost algorithm to see if it gives better results than the caret-trained one.
for example the early_stopping_rounds arg could maybe prevent overfitting.

```{r}

# create xgboost-friendly matrices for training the model

batter_train_labels <-
  batter_hof_train$vote_share %>%
  as.matrix()
batter_train_matrix <-
  batter_hof_train %>%
  dplyr::select(-vote_share) %>%
  as.matrix()
batter_dtrain <- xgb.DMatrix(
  data = batter_train_matrix,
  label = batter_train_labels
)

params <- list(
  objective = "reg:linear",
  eval_metric = "rmse",
  booster = "gbtree"
)

watchlist <- list(validation = batter_dtest, train = batter_dtrain)


# use 10-fold CV to determine the optimal number of iterations
batter_hof_xgb_mdl_params <- xgb.cv(
  params = params,
  data = batter_dtrain,
  nrounds = 500,
  nfold = 10,
  early_stopping_rounds = 50,
  stratified = TRUE
)

num_rounds <- batter_hof_xgb_mdl_params$best_iteration

# train model
batter_hof_xgb_mdl <- xgb.train(
  params = params,
  data = batter_dtrain,
  nrounds = num_rounds,
  early_stopping_rounds = 5,
  watchlist = watchlist
)

# construct xgboost-friendly test dataset, augment with model predictions, and evaluate model
batter_test_labels <- batter_hof_test$vote_share %>%
  as.matrix()
batter_test_matrix <-
  batter_hof_test %>%
  dplyr::select(-vote_share) %>%
  as.matrix()
batter_dtest <- xgb.DMatrix(
  data = batter_test_matrix,
  label = batter_test_labels
)

# evaluate model empirically
batter_xgb_predictions <-
  predict(batter_hof_xgb_mdl, newdata = batter_dtest) %>%
  as_tibble() %>%
  dplyr::select(predicted_vote_share = value) %>%
  bind_cols(batter_hof_test) %>%
  dplyr::select(vote_share, predicted_vote_share) %>%
  mutate(residual = vote_share - predicted_vote_share)

xgb_rmse <- round(RMSE(batter_xgb_predictions$predicted_vote_share, batter_xgb_predictions$vote_share), 1)

xgb_r_squared <- round(summary(lm(batter_xgb_predictions$predicted_vote_share ~ batter_xgb_predictions$vote_share))$r.squared, 2)

ggplot(batter_xgb_predictions, aes(vote_share, predicted_vote_share)) +
  geom_point() + geom_smooth(method = "lm") +
  geom_abline(linetype = "dashed") +
  ggtitle("Predicted Vote Share vs. Vote Share", subtitle = glue("R^2 = {xgb_r_squared}")) +
  labs(x = "Vote Share", y = "Predicted HOF Vote Share", caption = "Source: HOF Voting Data 1966-2018")

ggplot(batter_xgb_predictions, aes(vote_share, residual)) +
  geom_point() + geom_hline(yintercept = 0, linetype = "dashed") +
  ggtitle("Predicted Vote Share vs. Residuals", subtitle = glue("RMSE = {xgb_rmse}")) +
  labs(x="Predicted Vote Share", y="Residual")

# evaluate model subjectively using its 2019 predictions using model
data_2019 <- xgb.DMatrix(batter_voting_future_preprocessed %>%
  dplyr::select(-Name) %>%
  as.matrix())

xgb_predictions <-
  predict(batter_hof_xgb_mdl, newdata = data_2019) %>%
  as_tibble() %>%
  dplyr::select(predicted_vote_share = value) %>%
  mutate(predicted_vote_share = round(predicted_vote_share, 1)) %>%
  bind_cols(batter_voting_future_preprocessed %>%
    dplyr::select(Name, year_on_ballot)) %>%
  dplyr::select(Name, predicted_vote_share, everything()) %>%
  arrange(desc(predicted_vote_share)) %>%
  left_join(voting_trends, by = "Name") %>%
  dplyr::select(Name, year_on_ballot, predicted_vote_share, previous_year_vote_share = prev_year_vote_share) %>%
  mutate(change = predicted_vote_share - previous_year_vote_share)

xgb_predictions

xgb.importance(feature_names = names(batter_hof_test %>% dplyr::select(-vote_share)), model = batter_hof_xgb_mdl) %>%
  as_tibble() %>%
  ggplot(aes(reorder(Feature, Gain), Gain)) +
  geom_col() + coord_flip() + fgt
```



# now do it for starting pitchers!!

```{r}


# TODO: vote share+? index vote share to average that year, at position? helps compare players to peers

# get number of cy youngs won by each pitcher


algorithms <-
  c("lm", "svmRadial", "xgbTree", "xgbLinear", "knn", "gbm")

# for each algorithm listed, train a model and assess it using the held-out test set,
# gather its predictions into a tibble, and compute residuals
starter_model_evaluation <-
  algorithms %>%
  map_dfc(
    train_and_assess_model,
    starter_hof_train,
    starter_hof_test,
    "RMSE",
    "starter"
  ) %>%
  as_tibble() %>%
  bind_cols(starter_hof_test) %>%
  dplyr::select(vote_share, contains("predict_")) %>%
  gather(model_type, predicted_vote_share, contains("predict_")) %>%
  dplyr::select(model_type, predicted_vote_share, vote_share) %>%
  mutate(residual = vote_share - predicted_vote_share)

starter_model_evaluation %>%
  ggplot(aes(vote_share, predicted_vote_share)) +
  geom_point() + geom_smooth(method = "lm") +
  fgt + facet_wrap(vars(model_type)) +
  expand_limits(x = 0, y = 0) +
  geom_abline(linetype = "dashed") + ggtitle("Model Evaluation: Starter HOF Voting %")

starter_model_evaluation %>%
  ggplot(aes(predicted_vote_share, residual)) + geom_point() +
  facet_wrap(vars(model_type)) + fgt +
  geom_hline(yintercept = 0, linetype = "dashed") + ggtitle("Model Evaluation: Starter HOF Residuals")

starter_r_squared <-
  starter_model_evaluation %>%
  split(.$model_type) %>%
  map(~ lm(vote_share ~ predicted_vote_share, data = .)) %>%
  map(summary) %>%
  map_dbl("r.squared") %>%
  tidy() %>%
  dplyr::select(model_type = names, r_squared = x)

# display table of model evaluation statistics
starter_model_metrics <-
  starter_model_evaluation %>%
  group_by(model_type) %>%
  summarize(
    RMSE = RMSE(predicted_vote_share, vote_share),
    MAE = mean(abs(predicted_vote_share - vote_share))
  ) %>%
  inner_join(starter_r_squared, by = "model_type") %>%
  ungroup() %>%
  mutate(
    zr_squared = (r_squared - mean(r_squared)) / sd(r_squared),
    zRMSE = (RMSE - mean(RMSE)) / sd(RMSE),
    zMAE = (MAE - mean(MAE)) / sd(MAE),
    label = str_c(str_c(str_replace(model_type, "predict_", ""), ":"),
      "R^2:", str_c(round(r_squared, 2), ","),
      "RMSE:", round(RMSE, 1),
      sep = " "
    )
  ) %>%
  dplyr::select(`Model Type` = model_type, `R^2` = r_squared, RMSE, MAE, `zR^2` = zr_squared, zRMSE, zMAE, label)

ggplot(starter_model_metrics, aes(`zR^2`, zRMSE)) + geom_point() + fgt +
  geom_vline(xintercept = 0, linetype = "dashed") + geom_hline(yintercept = 0, linetype = "dashed") +
  geom_label_repel(aes(label = label)) +
  ggtitle("Evaluation Metrics of Models: Starter HOF Voting") +
  xlim(-2, 2) + ylim(-2, 2) + labs(x = "zR^2")
```

make 2019 predictions using chosen model

```{r}

predict(starter_hof_voting_model_xgbTree, newdata = starter_voting_future_preprocessed) %>%
  as_tibble() %>%
  dplyr::select(predicted_vote_share = value) %>%
  bind_cols(starter_predictions_processed) %>%
  dplyr::select(Name, predicted_vote_share, everything()) %>%
  mutate(predicted_vote_share = round(predicted_vote_share, 1)) %>%
  arrange(desc(predicted_vote_share)) %>%
  left_join(voting_trends, by = "Name") %>%
  dplyr::select(Name, year_on_ballot, predicted_vote_share, previous_year_vote_share = prev_year_vote_share.y) %>%
  mutate(change = predicted_vote_share - previous_year_vote_share)
```


"raw" xgboost for starting pitchers

```{r}

# create xgboost-friendly matrices for training the model
starter_train_labels <-
  starter_hof_train$vote_share %>%
  as.matrix()
starter_train_matrix <-
  starter_hof_train %>%
  dplyr::select(-vote_share) %>%
  as.matrix()
starter_dtrain <- xgb.DMatrix(
  data = starter_train_matrix,
  label = starter_train_labels
)

# construct xgboost-friendly test dataset
starter_test_labels <- starter_hof_test$vote_share %>%
  as.matrix()
starter_test_matrix <-
  starter_hof_test %>%
  dplyr::select(-vote_share) %>%
  as.matrix()
starter_dtest <- xgb.DMatrix(
  data = starter_test_matrix,
  label = starter_test_labels
)

params <- list(
  objective = "reg:linear",
  eval_metric = "rmse",
  booster = "gbtree"
)

starter_watchlist <- list(train = starter_dtrain, test = starter_dtest)

# use 10-fold CV to determine the optimal number of iterations
starter_hof_xgb_mdl_params <- xgb.cv(
  params = params,
  data = starter_dtrain,
  nrounds = 500,
  nfold = 10,
  early_stopping_rounds = 100,
  stratified = TRUE
)

starter_num_rounds <- starter_hof_xgb_mdl_params$best_iteration

# train model
starter_hof_xgb_mdl <- xgb.train(
  params = params,
  data = starter_dtrain,
  nrounds = starter_num_rounds
)

# evaluate model empirically
starter_xgb_predictions <-
  predict(starter_hof_xgb_mdl, newdata = starter_dtest) %>%
  as_tibble() %>%
  dplyr::select(predicted_vote_share = value) %>%
  bind_cols(starter_hof_test) %>%
  dplyr::select(vote_share, predicted_vote_share) %>%
  mutate(residual = vote_share - predicted_vote_share)

starter_xgb_rmse <- round(RMSE(starter_xgb_predictions$predicted_vote_share, starter_xgb_predictions$vote_share), 1)

starter_xgb_r_squared <- round(summary(lm(starter_xgb_predictions$predicted_vote_share ~ starter_xgb_predictions$vote_share))$r.squared, 2)

ggplot(starter_xgb_predictions, aes(vote_share, predicted_vote_share)) +
  geom_point() + geom_smooth(method = "lm") +
  geom_abline(linetype = "dashed") +
  ggtitle("Predicted Vote Share vs. Vote Share", subtitle = glue("R^2 = {starter_xgb_r_squared}")) +
  labs(x = "Vote Share", y = "Predicted HOF Vote Share", caption = "Source: HOF Voting Data 1966-2018")

ggplot(starter_xgb_predictions, aes(vote_share, residual)) +
  geom_point() + geom_hline(yintercept = 0, linetype = "dashed") +
  ggtitle("Predicted Vote Share vs. Residuals", subtitle = glue("RMSE = {starter_xgb_rmse}")) +
  labs(x="Predicted Vote Share", y="Residual")

# evaluate model subjectively using its 2019 predictions using model
starter_data_2019 <- 
  xgb.DMatrix(starter_voting_future_preprocessed %>%
  dplyr::select(-Name) %>%
  as.matrix())

starter_xgb_predictions <-
  predict(starter_hof_xgb_mdl, newdata = starter_data_2019) %>%
  as_tibble() %>%
  dplyr::select(predicted_vote_share = value) %>%
  mutate(predicted_vote_share = round(predicted_vote_share, 1)) %>%
  bind_cols(starter_voting_future_preprocessed %>%
    dplyr::select(Name, year_on_ballot)) %>%
  dplyr::select(Name, predicted_vote_share, everything()) %>%
  arrange(desc(predicted_vote_share)) %>%
  left_join(voting_trends, by = "Name") %>%
  dplyr::select(Name, year_on_ballot, predicted_vote_share, previous_year_vote_share = prev_year_vote_share) %>%
  mutate(change = predicted_vote_share - previous_year_vote_share)

starter_xgb_predictions

xgb.importance(feature_names = names(starter_hof_test %>% dplyr::select(-vote_share)), model = starter_hof_xgb_mdl) %>%
  as_tibble() %>%
  ggplot(aes(reorder(Feature, Gain), Gain)) +
  geom_col() + coord_flip() + fgt
```


lastly, predict relievers

```{r}

algorithms <-
  c("xgbTree", "xgbLinear", "knn", "rf")

reliever_model_evaluation <-
  algorithms %>%
  map_dfc(
    train_and_assess_model,
    reliever_hof_train,
    reliever_hof_test,
    "RMSE",
    "reliever"
  ) %>%
  as_tibble() %>%
  bind_cols(reliever_hof_test) %>%
  dplyr::select(vote_share, contains("predict_")) %>%
  gather(model_type, predicted_vote_share, contains("predict_")) %>%
  dplyr::select(model_type, predicted_vote_share, vote_share) %>%
  mutate(residual = vote_share - predicted_vote_share)

reliever_model_evaluation %>%
  ggplot(aes(vote_share, predicted_vote_share)) +
  geom_point() + geom_smooth(method = "lm") +
  fgt + facet_wrap(vars(model_type)) +
  expand_limits(x = 0, y = 0) +
  geom_abline(linetype = "dashed") + ggtitle("Model Evaluation: Reliever HOF Voting %")

reliever_model_evaluation %>%
  ggplot(aes(predicted_vote_share, residual)) + geom_point() +
  facet_wrap(vars(model_type)) + fgt +
  geom_hline(yintercept = 0, linetype = "dashed") + ggtitle("Model Evaluation: Reliever HOF Voting %")

reliever_r_squared <-
  reliever_model_evaluation %>%
  split(.$model_type) %>%
  map(~ lm(vote_share ~ predicted_vote_share, data = .)) %>%
  map(summary) %>%
  map_dbl("r.squared") %>%
  tidy() %>%
  dplyr::select(model_type = names, r_squared = x)

# display table of model evaluation statistics
reliever_model_metrics <-
  reliever_model_evaluation %>%
  group_by(model_type) %>%
  summarize(
    RMSE = RMSE(predicted_vote_share, vote_share),
    MAE = mean(abs(predicted_vote_share - vote_share))
  ) %>%
  inner_join(reliever_r_squared, by = "model_type") %>%
  ungroup() %>%
  mutate(
    zr_squared = (r_squared - mean(r_squared)) / sd(r_squared),
    zRMSE = (RMSE - mean(RMSE)) / sd(RMSE),
    zMAE = (MAE - mean(MAE)) / sd(MAE),
    label = str_c(str_c(str_replace(model_type, "predict_", ""), ":"),
      "R^2:", str_c(round(r_squared, 2), ","),
      "RMSE:", round(RMSE, 1),
      sep = " "
    )
  ) %>%
  dplyr::select(`Model Type` = model_type, `R^2` = r_squared, RMSE, MAE, `zR^2` = zr_squared, zRMSE, zMAE, label)

ggplot(reliever_model_metrics, aes(`zR^2`, zRMSE)) + geom_point() + fgt +
  geom_vline(xintercept = 0, linetype = "dashed") + geom_hline(yintercept = 0, linetype = "dashed") +
  geom_label_repel(aes(label = label)) +
  ggtitle("Evaluation Metrics of Models: Reliever HOF Voting %") +
  xlim(-2, 2) + ylim(-2, 2) + labs(x = "zR^2")
```

predict reliever vote share using best model

```{r}


predict(reliever_hof_voting_model_xgbTree, newdata = reliever_predictions_processed) %>%
  as_tibble() %>%
  dplyr::select(predicted_vote_share = value) %>%
  bind_cols(reliever_predictions_processed) %>%
  dplyr::select(Name, predicted_vote_share, everything()) %>%
  mutate(predicted_vote_share = round(predicted_vote_share, 1)) %>%
  arrange(desc(predicted_vote_share)) %>%
  left_join(voting_trends, by = "Name") %>%
  dplyr::select(Name, year_on_ballot, predicted_vote_share, previous_year_vote_share = prev_year_vote_share.y) %>%
  mutate(change = predicted_vote_share - previous_year_vote_share)
```






